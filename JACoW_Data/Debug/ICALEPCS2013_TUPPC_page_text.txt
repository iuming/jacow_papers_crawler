













ICALEPCS2013 - Table of Session: TUPPC (Poster 2 and Industrial Exhibition)


TUPPC —  Poster 2 and Industrial Exhibition   (08-Oct-13   13:30—15:00)



Paper
Title
Page



TUPPC003

SDD toolkit : ITER CODAC Platform for Configuration and Development
550


 

L. Abadie, F. Di Maio, D. Stepanov, A. Wallander
                       ITER Organization, St. Paul lez Durance, France
K. Bandaru, H. Deshmukh, P.J. Nanware, R. Patel
                       TCS France, Puteaux, France
G. Darcourt, A. Mariage
                       Sopra Group, Aix-en-Provence, France
A. Žagar
                       Cosylab, Ljubljana, Slovenia

 


 

ITER will consist of roughly 200 plant systems I&C (in total millions of variables) delivered in kind which need to be integrated into the ITER control infrastructure. To integrate them in a smooth way, CODAC team releases every year the Core Software environment which consists of many applications. This paper focuses on the self description data toolkit implementation, a fully home-made ITER product. The SDD model has been designed with Hibernate/Spring to provide required information to generate configuration files for CODAC services such as archiving, EPICS, alarm, SDN, basic HMIs, etc. Users enter their configuration data via GUIs based on web application and Eclipse. Snapshots of I&C projects can be dumped to XML. Different levels of validation corresponding to various stages of development have been implemented: it enables during integration, verification that I&C projects are compliant with our standards. The development of I&C projects continues with Maven utilities. In 2012, a new Eclipse perspective has been developed to allow user to develop codes, to start their projects, to develop new HMIs, to retrofit their data in SDD database and to checkout/commit from/to SVN.

 






Poster TUPPC003 [1.293 MB]
            
 


 



TUPPC004
Scalable Archiving with the Cassandra Archiver for CSS
554


 

S. Marsching
                       Aquenos GmbH, Baden-Baden, Germany

 


 

An archive for process-variable values is an important part of most supervisory control and data acquisition (SCADA) systems, because it allows operators to investigate past events, thus helping in identifying and resolving problems in the operation of the supervised facility. For large facilities like particle accelerators there can be more than one hundred thousand process variables that have to be archived. When these process variables change at a rate of one Hertz or more, a single computer system can typically not handle the data processing and storage. The Cassandra Archiver has been developed in order to provide a simple to use, scalable data-archiving solution. It seamlessly plugs into Control System Studio (CSS) providing quick and simple access to all archived process variables. An Apache Cassandra database is used for storing the data, automatically distributing it over many nodes and providing high-availability features. This contribution depicts the architecture of the Cassandra Archiver and presents performance benchmarks outlining the scalability and comparing it to traditional archiving solutions based on relational databases.

 






Poster TUPPC004 [3.304 MB]
            
 


 



TUPPC005
Implementation of an Overall Data Management at the Tomography Station at ANKA
558


 

D. Haas, W. Mexner, H. Pasic, T. Spangenberg
                       KIT, Eggenstein-Leopoldshafen, Germany

 


 

New technologies and research methods increase the complexity of data management at the beamlines of a synchrotron radiation facility. The diverse experimental data such as user and sample information, beamline status and parameters and experimental datasets, has to be interrelated, stored and provided to the user in a convenient way. The implementation of these requirements leads to challenges in fields of data life-cycle, storage, format and flow. At the tomography station at the ANKA a novel data management system has been introduced, representing a clearly structured and well organized data flow. The first step was to introduce the Experimental Coordination Service ECS, which reorganizes the measurement process and provides automatic linking of meta-, logging- and experimental-data. The huge amount of data, several TByte/week, is stored in NeXus files. These files are subsequently handled regarding storage location and life cycle by the WorkSpaceCreator development tool. In a further step ANKA will introduce the European single sign on system Umbrella and the experimental data catalogue ICAT as planned as the European standard solution in the PaNdata project.

 






Poster TUPPC005 [1.422 MB]
            
 


 



TUPPC006
Identifying Control Equipment
562


 

M.R. Clausen, M. Möller
                       DESY, Hamburg, Germany

 


 

The cryogenic installations at DESY are widely spread over the DESY campus. Many new components have been and will be installed for the new European XFEL. Commissioning and testing takes a lot of time. Local tag labels help identify the components but it is error prone to type in the names. Local bar-codes and/or datamatrix codes can be used in conjunction with intelligent devices like smart (i)Phones to retrieve data directly from the control system. The developed application will also show information from the asset database. This will provide the asset properties of the individual hardware device including the remaining warranty. Last not least cables are equipped with a bar-code which helps to identify start and endpoint of the cable and the related physical signal. This paper will describe our experience with the mobile applications and the related background databases which are operational already for several years.

 






Poster TUPPC006 [0.398 MB]
            
 


 



TUPPC008
A New Flexible Integration of NeXus Datasets to ANKA by Fuse File Systems
566


 

W. Mexner, E. Iurchenko, H. Pasic, D. Ressmann, T. Spangenberg
                       KIT, Karlsruhe, Germany

 


 

In the high data rate initiative (HDRI) german accelerator and neutron facilities of the Helmholtz Association agreed to use NeXus as a common data format. The synchrotron radiation source ANKA decided in 2012 to introduce NeXus as common data format for all beam lines. Nevertheless it is a challenging work to integrate a new data format in existing data processing work flows. Scientists rely on existing data evaluation kits which require specific data formats. To solve this obstacle, for linux a filesystem in userspace (FUSE) was developed, allowing to mount NeXus-Files as a filesystem. Easy in XML configurable filter rules allow a very flexible view to the data. Tomography data frames can be directly accessed as TIFF files by any standard picture viewer or scan data can be presented as a virtual ASCII file compatible to spec.

 


 



TUPPC011
Development of an Innovative Storage Manager for a Distributed Control System
570


 

C. Bisegni, G. Di Pirro, L.G. Foggetta, G. Mazzitelli, A. Stecchi
                       INFN/LNF, Frascati (Roma), Italy
L. Catani
                       INFN-Roma II, Roma, Italy
L. Catani
                       Università di Roma II Tor Vergata, Roma, Italy
M. Mara
                       Istituto Nazionale di Fisica Nucleare, Amministrazione Centrale, Frascati, Italy

 


 

The !CHAOS(*) framework will provide all the services needed for controlling and managing a large scientific infrastructure, including a number of innovating features such as abstraction of services, devices and data, easy and modular customization, extensive data caching for performance boost, integration of all functionalities in a common framework. One of most relevant innovation in !CHAOS resides in the History Data Service (HDS) for a continuous acquisition of operating data pushed by devices controllers. The core component of the HDS is the History engine(HST). It implements the abstraction layer for the underneath storage technology and the logics for indexing and querying data. The HST drivers are designed to provide specific HDS tasks such as Indexing, Caching and Storing, and for wrapping the chosen third-party database API with !CHOAS standard calls. Indeed, the HST allows to route to independent channels the different !CHAOS services data flow in order to improve the global efficiency of the whole data acquisition system.
* - http://chaos.infn.it  * - https://chaosframework.atlassian.net/wiki/display/DOC/General+View * - http://prst-ab.aps.org/abstract/PRSTAB/v15/i11/e112804

 






Poster TUPPC011 [6.729 MB]
            
 


 



TUPPC013
Scaling Out of the MADOCA Database System for SACLA
574


 

T. Hirono, T. Hamano, A. Yamashita
                       JASRI/SPring-8, Hyogo-ken, Japan
T. Fukui, K. Hagihara, T. Maruyama, K. Nemoto, M. Yamaga
                       RIKEN/SPring-8, Hyogo, Japan

 


 

MADOCA was adopted for the control system of SACLA, and the MADOCA database system was designed as a copy of the database system in SPring-8. The system realized a high redundancy because the system had already tested in SPring-8. However the signals which the MADOCA system handles in SACLA are increasing drastically. And GUIs that require frequent database accesses were developed. The load of the database system increased, and the response of the systems delayed in some occasions. We investigated the bottle neck of the system. From the results of the investigation, we decided to distribute the access to two servers. The primary server handles present data and signal properties. The other handles archived data, and the data was mounted to the primary server as a proxy table. In this way, we could divide the load into two servers and clients such as GUI do not need any changes. We have tested the load and response of the system by adding 40000 signals to present 45000 signals, of which data acquisition intervals are typically 2 sec. The system was installed successfully and operating without any interruption which is caused by the high load of the database.

 


 



TUPPC014
Development of SPring-8 Experimental Data Repository System for Management and Delivery of Experimental Data
577


 

H. Sakai, Y. Furukawa, T. Ohata
                       JASRI/SPring-8, Hyogo-ken, Japan

 


 

SPring-8 experimental Data Repository system (SP8DR) is an online storage service, which is built as one of the infrastructure services of SPring-8. SP8DR enables experimental user to obtain his experimental data, which was brought forth at SPring-8 beamline, on demand via the Internet. To make easy searching for required data-sets later, the system stored experimental data with meta-data such as experimental conditions. It is also useful to the post-experiment analysis process. As a framework for data management, we adopted DSpace that is widely used in the academic library information system. We made two kind of application software for registering an experimental data simply and quickly. These applications are used to record metadata-set to SP8DR database that has relations to experimental data on the storage system. This data management design allowed applications to high bandwidth data acquisition system. In this presentation, we report about the SPring-8 experimental Data Repository system that began operation in SPring-8 beamline.

 


 



TUPPC015
On-line and Off-line Data Analysis System for SACLA Experiments
580


 

T. Sugimoto, Y. Furukawa, Y. Joti, T.K. Kameshima, K. Okada, R. Tanaka, M. Yamaga
                       JASRI/SPring-8, Hyogo-ken, Japan
T. Abe
                       RIKEN SPring-8 Center, Innovative Light Sources Division, Hyogo, Japan

 


 

The X-ray Free-Electron Laser facility, SACLA, has delivered X-ray laser beams to users from March 2012 [1]. Typical user experiments utilize two-dimensional-imaging sensors, which generate 10 MBytes per accelerator beam shot. At 60 Hz beam repetition, the experimental data at the rate of 600 MBytes/second are accumulated using a dedicate data-acquisition (DAQ) system [2]. To analyze such a large amount of data, we developed data-analysis system for SACLA experiments. The system consists of on-line and off-line sections. The on-line section performs on-the-fly filtering using data handling servers, which examine data qualities and records the results onto the database with event-by-event basis. By referring the database, we can select good events before performing off-line analysis. The off-line section performs precise analysis by utilizing high-performance computing system, such as physical image reconstruction and rough three-dimensional structure analysis of the data samples. For the large-scaled image reconstructions, we also plan to use external supercomputer. In this paper, we present overview and future plan of the SACLA analysis system.
[1] T. Ishikawa et al., Nature Photonics 6, 540-544 (2012). [2] M. Yamaga et al., ICALEPCS 2011, TUCAUST06, 2011.

 






Poster TUPPC015 [10.437 MB]
            
 


 



TUPPC017
Development of J-PARC Time-Series Data Archiver using Distributed Database System
584


 

N. Kikuzawa, Y. Kato, A. Yoshii
                       JAEA/J-PARC, Tokai-Mura, Naka-Gun, Ibaraki-Ken, Japan
H. Ikeda
                       JAEA, Ibaraki-ken, Japan

 


 

J-PARC(Japan Proton Accelerator Research Complex) is consists of much equipment. In Linac and 3GeV synchrotron, the data of over the 64,000 EPICS records for these apparatus control is being collected. The data has been being stored by a RDB system using PostgreSQL now, but it is not enough in availability, performance, and extendibility. Therefore, the new system architecture is required, which is rich in the pliability and can respond to the data increasing continuously for years to come. In order to cope with this problem, we considered adoption of the distributed database archtecture and constructed the demonstration system using Hadoop/HBase. We present results of these demonstration.

 


 



TUPPC021
Monitoring and Archiving of NSLS-II Booster Synchrotron Parameters
587


 

A.A. Derbenev, P.B. Cheblakov, R.A. Kadyrov, S.E. Karnaev, S.S. Serednyakov, E.A. Simonov
                       BINP SB RAS, Novosibirsk, Russia
M.A. Davidsaver
                       BNL, Upton, New York, USA

 


 

When operating a multicomponent system, it is always necessary to observe the state of a whole installation as well as of its components. Tracking data is essential to perform tuning and troubleshooting, so records of a work process generally have to be kept. As any other machine, the NSLS-II booster should have an implementation of monitoring and archiving schemes as a part of the control system. Because of the booster being a facility with a cyclical operation mode, there were additional challenges when designing and developing monitoring and archiving tools. Thorough analysis of available infrastructure and current approaches to monitoring and archiving was conducted to take into account additional needs that come from booster special characteristics. A software extension for values present in the control system allowed to track the state of booster subsystems and to perform an advanced archiving with multiple warning levels. Time stamping and data collecting strategies were developed as a part of monitoring scheme in order to preserve and recover read-backs and settings as consistent data sets. This paper describes relevant solutions incorporated in the booster control system.

 






Poster TUPPC021 [0.589 MB]
            
 


 



TUPPC022
Centralized Software and Hardware Configuration Tool for Large and Small Experimental Physics Facilities
591


 

A.V. Makeev, N. Atuchin, D. Bolkhovityanov, P.B. Cheblakov, S.E. Karnaev
                       BINP SB RAS, Novosibirsk, Russia

 


 

All software of control system, starting from hardware drivers and up to user space PC applications, needs configuration information to work properly. This information includes such parameters as channels calibrations, network addresses, servers responsibilities and other. Each software subsystem requires a part of configuration parameters, but storing them separately from whole configuration will cause usability and reliability issues. On the other hand, storing all configuration in one centralized database will decrease software development speed, by adding extra central database querying. The paper proposes configuration tool that has advantages of both ways. Firstly, it uses a centralized configurable graph database, that could be manipulated by web-interface. Secondly, it could automatically export configuration information from centralized database to any local configuration storage. The tool has been developed at BINP (Novosibirsk, Russia) and is used to configure VEPP-2000 electron-positron collider (BINP, Russia), Electron Linear Induction Accelerator (Snezhinsk, Russia) and NSLS-II booster synchrotron (BNL, USA).

 






Poster TUPPC022 [1.441 MB]
            
 


 



TUPPC023
MeerKAT Poster and Demo Control and Monitoring Highlights
594


 

C.C.A. de Villiers
                       SKA South Africa, National Research Foundation of South Africa, Cape Town, South Africa

 


 

The 64-dish MeerKAT Karoo Array Telescope, currently under development, will become the largest and most sensitive radio telescope in the Southern Hemisphere until the Square Kilometre Array (SKA) is completed around 2024. MeerKAT will ultimately become an integral part of the SKA. The MeerKAT project will build on the techniques and experience acquired during the development of KAT-7, a 7-dish engineering prototype that has already proved its worth in practical use, operating 24/7 to deliver useful science data in the Karoo. Much of the MeerKAT development will centre on further refinement and scaling of the technology, using lessons learned from KAT-7. The poster session will present the proposed MeerKAT CAM (Control & Monitoring) architecture and highlight the solutions we are exploring for system monitoring, control and scheduling, data archiving and retrieval, and human interaction with the system. We will supplement the poster session with a live demonstration of the present KAT-7 CAM system. This will include a live video feed from the site as well as the use of the current GUI to generate and display the flow of events and data in a typical observation.  

 






Poster TUPPC023 [0.471 MB]
            
 


 



TUPPC024
Challenges to Providing a Successful Central Configuration Service to Support CERN’s New Controls Diagnostics and Monitoring System
596


 

Z. Makonnen, M. Buttner, Z. Zaharieva
                       CERN, Geneva, Switzerland

 


 

The Controls Diagnostic and Monitoring service (DIAMON) provides monitoring and diagnostics tools to the operators in the CERN Control Centre. A recent reengineering presented the opportunity to restructure its data management and to integrate it with the central Controls Configuration Service (CCS). The CCS provides the Configuration Management for the Controls System for all accelerators at CERN. The new facility had to cater for the configuration management of all agents monitored by DIAMON, (>3000 computers of different types), provide deployment information, relations between metrics, and historical information. In addition, it had to be integrated into the operational CCS, while ensuring stability and data coherency. An important design decision was to largely reuse the existing infrastructure in the CCS and adapt the DIAMON data management to it e.g. by using the device/property model through a Virtual Devices framework to model the DIAMON agents. This article will show how these challenging requirements were successfully met, the problems encountered and their resolution. The new service architecture will be presented: database model, new and tailored processes and tools.

 






Poster TUPPC024 [2.741 MB]
            
 


 



TUPPC025
Advantages and Challenges to the Use of On-line Feedback in CERN’s Accelerators Controls Configuration Management
600


 

Z. Zaharieva, S. Jensen, J. Rolland Lopez De Coca, A. Romero Marin
                       CERN, Geneva, Switzerland

 


 

The Controls Configuration Service (CCS) provides the Configuration Management facilities for the Controls System for all CERN accelerators. It complies with Configuration Management standards, tracking the life of configuration items and their relationships by allowing identification and triggering change management processes. Data stored in the CCS is extracted and propagated to the controls hardware for remote configuration. The article will present the ability of the CCS to audit items and verify conformance to specification with the implementation of on-line feedback focusing on Front-End Computers (FEC) configurations. Long-standing problems existed in this area such as discrepancies between the actual state of the FEC and the configuration sent to it at reboot. This resulted in difficult-to-diagnose behaviour and disturbance for the Operations team. The article will discuss the solution architecture (tailored processes and tools), the development and implementation challenges, as well as the advantages of this approach and the benefits to the user groups – from equipment specialists and controls systems experts to the operators in the Accelerators Controls Centre.

 






Poster TUPPC025 [3.937 MB]
            
 


 



TUPPC026
Concept and Prototype for a Distributed Analysis Framework for the LHC Machine Data
604


 

K. Fuchsberger, J.C. Garnier, A.A. Gorzawski, E. Motesnitsalis
                       CERN, Geneva, Switzerland

 


 

The Large Hadron Collider (LHC) at CERN produces more than 50 TB of diagnostic data every year, shared between normal running periods as well as commissioning periods. The data is collected in different systems, like the LHC Post Mortem System (PM), the LHC Logging Database and different file catalogues. To analyse and correlate data from these systems it is necessary to extract data to a local workspace and to use scripts to obtain and correlate the required information. Since the amount of data can be huge (depending on the task to be achieved) this approach can be very inefficient. To cope with this problem, a new project was launched to bring the analysis closer to the data itself. This paper describes the concepts and the implementation of the first prototype of an extensible framework, which will allow integrating all the existing data sources as well as future extensions, like hadoop* clusters or other parallelization frameworks.
*http://hadoop.apache.org/

 






Poster TUPPC026 [1.378 MB]
            
 


 



TUPPC027
Quality Management of CERN Vacuum Controls
608


 

F. Antoniotti, J-P. Boivin, E. Fortescue-Beck, J. Gama, P. Gomes, P. Le Roux, H.F. Pereira, G. Pigny
                       CERN, Geneva, Switzerland

 


 

The vacuum controls team is in charge of the monitoring, maintenance & consolidation of the control systems of all accelerators and detectors in CERN; this represents 6 000 instruments distributed along 128 km of vacuum chambers, often of heterogeneous architectures. In order to improve the efficiency of the services we provide, to vacuum experts and to accelerator operators, a Quality Management Plan is being put into place. The first step was the gathering of old documents and the centralisation of information concerning architectures, procedures, equipment and settings. It was followed by the standardisation of the naming convention across different accelerators. The traceability of problems, request, repairs, and other actions, has also been put into place. It goes together with the effort on identification of each individual device by a coded label, and its registration in a central database. We are also working on ways to record, retrieve, process, and display the information across several linked repositories; then, the quality and efficiency of our services can only improve, and the corresponding performance indicators will be available.

 






Poster TUPPC027 [98.542 MB]
            
 


 



TUPPC028
The CERN Accelerator Logging Service - 10 Years in Operation: A Look at the Past, Present, and Future
612


 

C. Roderick, L. Burdzanowski, G. Kruk
                       CERN, Geneva, Switzerland

 


 

During the 10 years since it's first operational use, the scope and scale of the CERN Accelerator Logging Service (LS) has evolved significantly: from an LHC specific service expected to store 1TB / year; to a CERN-wide service spanning the complete accelerator complex (including related sub-systems and experiments) currently storing more than 50 TB / year on-line for some 1 million signals. Despite the massive increase over initial expectations the LS remains reliable, and highly usable - this can be attested to by the 5 million daily / average number of data extraction requests, from close to 1000 users. Although a highly successful service, demands on the LS are expected to increase significantly as CERN prepares LHC for running at top energy, which is likely to result in at least doubling current data volumes. Furthermore, focus is now shifting firmly towards a need to perform complex analysis on logged data, which in-turn presents new challenges. This paper reflects on 10 years as an operational service, in terms of how it has managed to scale to meet growing demands, what has worked well, and lessons learned. On-going developments, and future evolution will also be discussed.

 






Poster TUPPC028 [3.130 MB]
            
 


 



TUPPC029
Integration, Processing, Analysis Methodologies and Tools for Ensuring High Data Quality and Rapid Data Access in the TIM* Monitoring System
615


 

A. Suwalska, M. Brightwell, M. Bräger, E. Koufakis, R. Martini, P. Sollander
                       CERN, Geneva, Switzerland

 


 

Processing, storing and analysing large amounts of real-time data is a challenge for every monitoring system. The performance of the system strongly depends on high quality configuration data and the ability of the system to cope with data anomalies. The Technical Infrastructure Monitoring system (TIM) addresses data quality issues by enforcing a workflow of strict procedures to integrate or modify data tag configurations. TIM’s data acquisition layer architecture allows real-time analysis and rejection of irrelevant data. The discarded raw data 90,000,000 transactions/day) are stored in a database, then purged after gathering statistics. The remaining operational data (2,000,000 transactions/day) are transferred to a server running an in-memory database, ensuring its rapid processing. These data are currently stored for 30 days allowing ad hoc historical data analysis. In this paper we describe the methods and tools used to guarantee the quality of configuration data and highlight the advanced architecture that ensures optimal access to operational data as well as the tools used to perform off-line data analysis.
* Technical Infrastructure Monitoring system

 






Poster TUPPC029 [0.742 MB]
            
 


 



TUPPC030
System Relation Management and Status Tracking for CERN Accelerator Systems
619


 

J.C. Garnier, M. Audrain, D. Csikos, K. Fuchsberger, A.A. Gorzawski, G. Horanyi, J. Suchowski, P.C. Turcu, M. Zerlauth
                       CERN, Geneva, Switzerland

 


 

The Large Hadron Collider (LHC) at CERN requires many systems to work in close interplay to allow reliable operation and at the same time ensure the correct functioning of the protection systems required when operating with large energies stored in magnet system and particle beams. Examples for systems are e.g. magnets, power converters, quench protection systems as well as higher level systems like java applications or server processes. All these systems have numerous and different kind of links (dependencies) between each other. The knowledge about the different dependencies is available from different sources, like Layout databases, Java imports, proprietary files, etc. Retrieving consistent information is difficult due to the lack of a unified way of retrieval for the relevant data. This paper describes a new approach to establish a central server instance, which allows collecting this information and providing it to different clients used during commissioning and operation of the accelerator. Furthermore, it explains future visions for such a system, which includes additional layers for distributing system information like operational status, issues or faults.

 






Poster TUPPC030 [4.175 MB]
            
 


 



TUPPC031
Proteus: FRIB Configuration Database
623


 

V. Vuppala, E.T. Berryman
                       NSCL, East Lansing, Michigan, USA
L.R. Dalesio
                       BNL, Upton, Long Island, New York, USA
S. Peng
                       FRIB, East Lansing, USA

 


 

Distributed Information Services for Control Systems (DISCS) is a framework for developing high-level information systems for a Experimental Physics Facility. It comprises of a set of cooperating components. Each component of the system has a database, an API, and several applications. One of DISCS' core components is the Configuration Module. It is responsible for the management of devices, their layout, measurements, alignment, calibration, signals, and inventory. In this paper we describe FRIB's implementation of the Configuration Module - Proteus. We describe its architecture, database schema, web-based GUI, EPICS V4 and REST services, and Java/Python APIs. It has been developed as a product that other labs can download and use. It can be integrated with other independent systems. We describe the challenges to implementing such a system, our technology choices, and the lessons learnt.

 






Poster TUPPC031 [1.248 MB]
            
 


 



TUPPC032
Database-backed Configuration Service
627


 

J.A. Mader, J.M. Johnson, K.T. Tsubota
                       W.M. Keck Observatory, Kamuela, USA

 


 

Keck Observatory is in the midst of a major telescope control system upgrade. This upgrade will include a new database-backed configuration service which will be used to manage the many aspects of the telescope that need to be configured (e.g. site parameters, control tuning, limit values) for its control software and it will keep the configuration data persistent between IOC restarts. This paper will discuss this new configuration service, including its database schema, iocsh API, rich user interface and the many other provided features. The solution provides automatic time-stamping, a history of all database changes, the ability to snapshot and load different configurations and triggers to manage the integrity of the data collections. Configuration is based on a simple concept of controllers, components and their associated mapping. The solution also provides a failsafe mode that allows client IOCs to function if there is a problem with the database server. It will also discuss why this new service is preferred over the file based configuration tools that have been used at Keck up to now.

 






Poster TUPPC032 [0.849 MB]
            
 


 



TUPPC034
Experience Improving the Performance of Reading and Displaying Very Large Datasets
630


 

T. D'Ottavio, B. Frak, J. Morris, S. Nemesure
                       BNL, Upton, Long Island, New York, USA

 


 

Funding: Work supported by Brookhaven Science Associates, LLC under Contract No. DE-AC02-98CH10886 with the U.S. Department of Energy.
There has been an increasing need over the last 5 years within the BNL accelerator community (primarily within the RF and Instrumentation groups) to collect, store and display data at high frequencies (1-10 kHz). Data throughput considerations when storing this data are manageable. But requests to display gigabytes of the collected data can quickly tax the speed at which data can be read from storage, transported over a network, and displayed on a users computer monitor. This paper reports on efforts to improve the performance of both reading and displaying data collected by our data logging system. Our primary means of improving performance was to build an Data Server – a hardware/software server solution built to respond to client requests for data. It's job is to improve performance by 1) improving the speed at which data is read from disk, and 2) culling the data so that the returned datasets are visually indistinguishable from the requested datasets. This paper reports on statistics that we've accumulated over the last two years that show improved data processing speeds and associated increases in the number and average size of client requests.

 






Poster TUPPC034 [1.812 MB]
            
 


 



TUPPC035
A New EPICS Archiver
632


 

N. Malitsky, D. Dohan
                       BNL, Upton, Long Island, New York, USA

 


 

This report presents a large-scale high-performance distributed data storage system for acquiring and processing time series data of modern accelerator facilities. Derived from the original EPICS Channel Archiver, this version consistently extends it through the integration of the deliberately selected technologies, such as the HDF5 file format, the SciDB chunk-oriented interface, and the RDB-based representation of the DDS X-Types specification. The changes allowed to scale the performance of the new version towards the data rates of 500 K scalar samples per seconds. Moreover, the new EPICS Archiver provides a common platform for managing both the EPICS 3 records and composite data types, like images, of EPICS 4 applications.

 






Poster TUPPC035 [0.247 MB]
            
 


 



TUPPC036
A Status Update on Hyppie – a Hyppervisored PXI for Physics Instrumentation under EPICS
635


 

J.R. Piton, M.P. Donadio, D.O. Omitto, M.A. Raulik
                       LNLS, Campinas, Brazil

 


 

Beamlines at LNLS are moving to the concept of distributed control under EPICS. This has being done by reusing available code from the community and/or by programming hardware access in LabVIEW integrated to EPICS through Hyppie. Hyppie is a project to make a bridge between EPICS records and corresponding devices in a PXI chassis. Both EPICS/Linux and LabVIEW Real-Time run simultaneously in the same PXI controller, in a virtualization system with a common memory block shared as their communication interface. A number of new devices were introduced in the Hyppie suite and LNLS beamlines are experiencing a smooth transition to the new concept.

 






Poster TUPPC036 [1.658 MB]
            
 


 



TUPPC037
LabWeb - LNLS Beamlines Remote Operation System
638


 

H.H. Slepicka, M.A. Barbosa, R. Bongers, H.F. Canova, M.B. Cardoso, J.C. Mauricio, D.O. Omitto, J.M. Polli, C.B. Rodella, H. Westfahl Jr., M.M. Xavier, D.C. de Oliveira
                       LNLS, Campinas, Brazil

 


 

Funding: Project funded by CENPES/PETROBRAS under contract number: 0050.0067267.11.9
LabWeb is a software developed to allow remote operation of beamlines at LNLS, in a partnership with Petrobras Nanotechnology Network. Being the only light source in Latin America, LNLS receives many researchers and students interested in conducting experiments and analyses in these lines. The implementation of LabWeb allow researchers to use the laboratory structure without leaving their research centers, reducing time and travel costs in a continental country like Brazil. In 2010, the project was in its first phase in which tests were conducted using a beta version. Two years later, a new phase of the project began with the main goal of giving the operation scale for the remote access project to LNLS users. In this new version, a partnership was established to use the open source platform Science Studio developed and applied at the Canadian Light Source (CLS). Currently, the project includes remote operation of three beamlines at LNLS: SAXS1 (Small Angle X-Ray Scattering), XAFS1 (X-Ray Absorption and Fluorescence Spectroscopy) and XRD1 (X-Ray Diffraction). Now, the expectation is to provide this new way of realize experiments to all the other beamlines at LNLS.

 






Poster TUPPC037 [1.613 MB]
            
 


 



TUPPC038
Simultaneous On-line Ultrasonic Flowmetery and Binary Gas Mixture Analysis for the ATLAS Silicon Tracker Cooling Control System
642


 

M. Doubek, V. Vacek, M. Vitek
                       Czech Technical University in Prague, Faculty of Mechanical Engineering, Prague, Czech Republic
R.L. Bates, A. Bitadze
                       University of Glasgow, Glasgow, Scotland, United Kingdom
M. Battistin, S. Berry, J. Berthoud, P. Bonneau, J. Botelho-Direito, G. Bozza, O. Crespo-Lopez, E. Da Riva, B. Di Girolamo, G. Favre, J. Godlewski, D. Lombard, L. Zwalinski
                       CERN, Geneva, Switzerland
N. Bousson, G.D. Hallewell, M. Mathieu, A. Rozanov
                       CPPM, Marseille, France
G. Boyd
                       University of Oklahoma, Norman, Oklahoma, USA
C. Degeorge
                       Indiana University, Bloomington, Indiana, USA
C. Deterre
                       DESY, Hamburg, Germany
S. Katunin
                       PNPI, Gatchina, Leningrad District, Russia
S. McMahon
                       STFC/RAL, Chilton, Didcot, Oxon, United Kingdom
K. Nagai
                       University of Tsukuba, Graduate School of Pure and Applied Sciences,, Tsukuba, Ibaraki, Japan
C. Rossi
                       Università degli Studi di Genova, Genova, Italy

 


 

We describe a combined ultrasonic instrument for continuous gas flow measurement and simultaneous real-time binary gas mixture analysis. The analysis algorithm compares real time measurements with a stored data base of sound velocity vs. gas composition. The instrument was developed for the ATLAS silicon tracker evaporative cooling system where C3F8 refrigerant may be replaced by a blend with 25% C2F6, allowing a lower evaporation temperature as the LHC luminosity increases. The instrument has been developed in two geometries. A version with an axial sound path has demonstrated a 1 % Full Scale precision for flows up to 230 l/min. A resolution of 0.3% is seen in C3F8/C2F6 molar mixtures, and a sensitivity of better than 0.005% to traces of C3F8 in nitrogen, during a 1 year continuous study in a system with sequenced multi-stream sampling. A high flow version has demonstrated a resolution of 1.9 % Full Scale for flows up to 7500 l/min. The instrument can provide rapid feedback in control systems operating with refrigerants or binary gas mixtures in detector applications. Other uses include anesthesia, analysis of hydrocarbons and vapor mixtures for semiconductor manufacture.
* Comm. author: martin.doubek@cern.ch  Refs  R. Bates et al. Combined ultrasonic flow meter & binary vapour analyzer for ATLAS 2013 JINST 8 C01002 

 






Poster TUPPC038 [1.834 MB]
            
 


 



TUPPC039
Development of a High-speed Diagnostics Package for the 0.2 J, 20 fs, 1 kHz Repetition Rate Laser at ELI Beamlines
646


 

J. Naylon, D.K. Kramer
                       ELI-BEAMS, Prague, Czech Republic

 


 

The ELI Beamlines facility aims to provide a selection of high repetition rate terawatt and petawatt femtosecond pulsed lasers, with applications in plasma research, particle acceleration, high-field physics and high intensity extended-UV/X-ray generation. The highest rate laser in the facility will be a 1 kHz femtosecond laser with pulse energy of 200 mJ. This high repetition rate presents unique challenges for the control system, particularly the diagnostics package. This is tasked with measuring key laser parameters such as pulse energy, pointing accuracy, and beam profile. Not only must this system be capable of relaying individual pulse measurements in real-time to the six experimental target chambers, it must also respond with microsecond latency to any aberrations indicating component damage or failure. We discuss the development and testing of a prototype near-field camera profiling system forming part of this diagnostics package consisting of a 1000 fps high resolution camera and FPGA-based beam profile and aberration detection system.

 






Poster TUPPC039 [2.244 MB]
            
 


 



TUPPC040
Saclay GBAR Command Control
650


 

P. Lotrus
                       CEA, Gif-sur-Yvette, France
G.A. Durand
                       CEA/DSM/IRFU, France

 


 

The GBAR experiment will be installed in 2016 at CERN’s Antiproton Decelerator, ELENA extension, and will measure the free fall acceleration of neutral antihydrogen atoms. Before construction of GBAR, the CEA/Irfu institute has built a beam line to guide positrons produced by a Linac (linear particle accelerator) through either a materials science line or a Penning trap. The experiment command control is mainly based on Programmable Logical Controllers (PLC). A CEA/Irfu-developed Muscade SCADA (Supervisory Control and Data Acquisition) is installed on a Windows 7 embedded shoebox PC. It manages local and remote display, and is responsible for archiving and alarms. Muscade was used because it is rapidly and easily configurable. The project required Muscade to communicate with three different types of PLCs: Schneider, National Instruments (NI) and Siemens. Communication is based on Modbus/TCP and on an in-house protocol optimized for the Siemens PLC. To share information between fast and slow controls, a LabVIEW PC dedicated to the trap fast control communicates with a PLC dedicated to security via Profinet fieldbus.

 






Poster TUPPC040 [1.791 MB]
            
 


 



TUPPC042
Prototype of a Simple ZeroMQ-Based RPC in Replacement of CORBA in NOMAD
654


 

Y. Le Goc, F. Cecillon, C. Cocho, A. Elaazzouzi, J. Locatelli, P. Mutti, H. Ortiz, J. Ratel
                       ILL, Grenoble, France

 


 

The NOMAD instrument control software of the Institut Laue-Langevin is a client server application. The communication between the server and its clients is performed with CORBA, which has now major drawbacks like the lack of support and a slow or non-existing evolution. The present paper describes the implementation of the recent and promising ZeroMQ technology in replacement to CORBA. We present the prototype of a simple RPC built on top of ZeroMQ and the performant Google Protocol Buffers serialization tool, to which we add a remote method dispatch layer. The final project will also provide an IDL compiler restricted to a subset of the language so that only minor modifications to our existing IDL interfaces and class implementations will have to be made to replace the communication layer in NOMAD.

 






Poster TUPPC042 [1.637 MB]
            
 


 



TUPPC043
Controlling Cilex-Apollon Laser Beams Alignment and Diagnostics Systems with Tango
658


 

M. Pina, B. Breteau, J-L. Paillard, J-L. Veray
                       LULI, Palaiseaux, France

 


 

Funding: CNRS, MESR, CG91, CRiDF, ANR
Cilex-Apollon is a high intensity laser facility delivering at least 5 PW pulses on targets at one shot per minute, to study physics such as laser plasma electron or ion accelerator and laser plasma X-Ray sources. Under construction, Apollon is a four beam laser installation with two target areas. To control the laser beam characteristics and alignment, more than 75 CCD cameras and 100 motors are dispatched in the facility and controlled through a Tango bus. The image acquisition and display are made at 10 Hz. Different operations are made on line, at the same rate on acquired images like binarisation, centroid calculation, size and energy of laser beam. Other operations are made off line, on stored images. The beam alignment can be operated manually or automatically. The automatic mode is based on a close loop using a transfer matrix and can correct the laser beam centering and pointing 5 times per second. The article presents the architecture, functionality, performances and feedback from a first deployment on a demonstrator.

 






Poster TUPPC043 [0.766 MB]
            
 


 



TUPPC044
When Hardware and Software Work in Concert
661


 

M. Vogelgesang, T. Baumbach, T. Farago, A. Kopmann, T. dos Santos Rolo
                       KIT, Eggenstein-Leopoldshafen, Germany

 


 

Funding: Partially funded by BMBF under the grants 05K10CKB and 05K10VKE.
Integrating control and high-speed data processing is a fundamental requirement to operate a beam line efficiently and improve user's beam time experience. Implementing such control environments for data intensive applications at synchrotrons has been difficult because of vendor-specific device access protocols and distributed components. Although TANGO addresses the distributed nature of experiment instrumentation, standardized APIs that provide uniform device access, process control and data analysis are still missing. Concert is a Python-based framework for device control and messaging. It implements these programming interfaces and provides a simple but powerful user interface. Our system exploits the asynchronous nature of device accesses and performs low-latency on-line data analysis using GPU-based data processing. We will use Concert to conduct experiments to adjust experimental conditions using on-line data analysis, e.g. during radiographic and tomographic experiments. Concert's process control mechanisms and the UFO processing framework* will allow us to control the process under study and the measuring procedure depending on image dynamics.
* Vogelgesang, Chilingaryan, Rolo, Kopmann: “UFO: A Scalable GPU-based Image Processing Framework for On-line Monitoring”

 






Poster TUPPC044 [4.318 MB]
            
 


 



TUPPC045
Software Development for High Speed Data Recording and Processing
665


 

D. Boukhelef, J. Szuba, K. Wrona, C. Youngman
                       XFEL. EU, Hamburg, Germany

 


 

Funding: The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007-2013) under grant agreement n° 283745.
The European XFEL beam delivery defines a unique time structure that requires acquiring and processing data in short bursts of up to 2700 images every 100 ms. The 2D pixel detectors being developed produce up to 10 GB/s of 1-Mpixel image data. Efficient handling of this huge data volume requires large network bandwidth and computing capabilities. The architecture of the DAQ system is hierarchical and modular. The DAQ network uses 10 GbE switched links to provide large bandwidth data transport between the front-end interfaces (FEI), data handling PC layer servers, and storage and analysis clusters. Front-end interfaces are required to build images acquired during a burst into pulse ordered image trains and forward them to PC layer farm. The PC layer consists of dedicated high-performance computers for raw data monitoring, processing and filtering, and aggregating data files that are then distributed to on-line storage and data analysis clusters. In this contribution we give an overview of the DAQ system architecture, communication protocols, as well as software stack for data acquisition pre-processing, monitoring, storage and analysis.

 






Poster TUPPC045 [1.323 MB]
            
 


 



TUPPC046
Control Using Beckhoff Distributed Rail Systems at the European XFEL
669


 

N. Coppola, J. Tolkiehn, C. Youngman
                       XFEL. EU, Hamburg, Germany

 


 

The European XFEL project is a 4th generation light source producing spatially coherent 80fs short photon x-ray pulses with a peak brilliance of 1032-1034 photons/s/mm2/mrad2/0.1% BW in the energy range from 0.26 to 24 keV at an electron beam energy 14 GeV. Six experiment stations will start data taking in fall 2015. In order to provide a simple, homogeneous solution, the DAQ and control systems group at the European XFEL are standardizing on COTS control hardware for use in experiment and photon beam line tunnels. A common factor within this standardization requirement is the integration with the Karabo software framework of Beckhoff TwinCAT 2.11 or TwinCAT3 PLCs and EtherCAT. The latter provides the high degree of reliability required and the desirable characteristics of real time capability, fast I/O channels, distributed flexible terminal topologies, and low cost per channel. In this contribution we describe how Beckhoff PLC and EtherCAT terminals will be used to control experiment and beam line systems. This allows a high degree of standardization for control and monitoring of systems.
Hardware Technology - POSTER

 






Poster TUPPC046 [1.658 MB]
            
 


 



TUPPC047
The New TANGO-based Control and Data Acquisition System of the GISAXS Instrument GALAXI at Forschungszentrum Jülich
673


 

H. Kleines, A. Ackens, M. Bednarek, K. Bussmann, M. Drochner, L. Fleischhauer-Fuss, M. Heinzler, P. Kaemmerling, F.-J. Kayser, S. Kirstein, K.-H. Mertens, R. Möller, U. Rücker, F. Suxdorf, M. Wagener, S. van Waasen
                       FZJ, Jülich, Germany

 


 

Forschungszentrum Jülich operated the SAXS instrument JUSIFA at DESY in Hamburg for more than twenty years. With the shutdown of the DORIS ring JUSIFA was relocated to Jülich. Based on most JUSIFA components (with major mechanical modifications) and a MetalJet high performance X-Ray source from Bruker AXS the new GISAXS instrument GALAXI was built by JCNS (Jülich Centre for Neutron Science). GALAXI was equipped with new electronics and a completely new control and data acquisition system by ZEA-2 (Zentralinstitut für Engineering, Elektronik und Analytik 2 – Systeme der Elektronik, formely ZEL). On the base of good experience with the TACO control system, ZEA-2 decided that GALAXI should be the first instrument of Forschungszentrum Jülich with the successor system TANGO. The application software on top of TANGO is based on pyfrid. Pyfrid was originally developed for the neutron scattering instruments of JCNS and provides a scripting interface as well as a Web GUI. The design of the new control and data acquisition system is presented and the lessons learned by the introduction of TANGO are reported.

 


 



TUPPC048
Adoption of the "PyFRID" Python Framework for Neutron Scattering Instruments
677


 

M. Drochner
                       FZJ, Jülich, Germany

 


 

M.Drochner, L.Fleischhauer-Fuss, H.Kleines, D.Korolkov, M.Wagener, S.v.Waasen Adoption of the "PyFRID" Python Framework for Neutron Scattering Instruments To unify the user interfaces of the JCNS (Jülich Centre for Neutron Science) scattering instruments, we are adapting and extending the "PyFRID" framework. "PyFRID" is a high-level Python framework for instrument control. It provides a high level of abstraction, particularly by use of aspect oriented (AOP) techniques. Users can use a builtin command language or a web interface to control and monitor motors, sensors, detectors and other instrument components. The framework has been fully adopted at two instruments, and work is in progress to use it on more.

 


 



TUPPC050
Control, Safety and Diagnostics for Future ATLAS Pixel Detectors
679


 

S. Kersten, P. Kind, P. Mättig, L. Puellen, S. Weber, C. Zeitnitz
                       Bergische Universität Wuppertal, Wuppertal, Germany
F. Gensolen
                       CPPM, Marseille, France
S. Kovalenko, K. Lantzsch
                       CERN, Geneva, Switzerland

 


 

To ensure the excellent performance of the ATLAS Pixel detector during the next run periods of the LHC, with increasing demands, two upgrades of the pixel detector are foreseen. One takes place in the first long shutdown, which is currently on-going. During this period an additional layer, the Insertable B-Layer, will be installed. The second upgrade will replace the entire pixel detector and is planed for 2020, when the LHC will be upgraded to HL-LHC. As once installed no access is possible over years, a highly reliable control system is required. It has to supply the detector with all entities required for operation, protect it at all times, and provide detailed information to diagnose the detector’s behaviour. Design constraints are the sensitivity of the sensors and reduction of material inside the tracker volume. We report on the construction of the control system for the Insertable B Layer and present a concept for the control of the pixel detector at the HL-LHC. While the latter requires completely new strategies, the control system of the IBL includes single new components, which can be developed further for the long-term upgrade.

 






Poster TUPPC050 [0.566 MB]
            
 


 



TUPPC052
Automation of the Wavelength Change for the FERMI Free Electron Laser
683


 

C. Scafuri, B. Diviacco
                       Elettra-Sincrotrone Trieste S.C.p.A., Basovizza, Italy

 


 

Funding: Work supported in part by the Italian Ministry of University and Research under grants FIRB-RBAP045JF2 and FIRB-RBAP06AWK3
FERMI is a users facility based on a seeded Free Electron Laser (FEL). A unique feature of FERMI in this new class of light sources is the tunability of the emitted photon beam both in terms of wavelength and polarization. Tuning is obtained by choosing the appropriate gap and phasing of the undulators in the chain and by opportunely setting the seed laser wavelength. A series of adjustments are then necessary in order to keep constant the machine parameters and optimize the radiation characteristics. We have developed a software application, named SuperGap, which does all the calculations and coordinates the operations required to set the desired wavelength and polarization. SuperGap allows operators to perform this procedure in seconds. The speed and accuracy of the wavelength change have been largely exploited during user dedicated shifts to perform various types of scans in the experimental stations. The paper describes the algorithms and numerical techniques used by SuperGap and its architecture based on the Tango control system.

 






Poster TUPPC052 [1.116 MB]
            
 


 



TUPPC053
New Control System for the SPES Off-line Laboratory at LNL-INFN using EPICS IOCs based on the Raspberry Pi
687


 

J.A. Vásquez, A. Andrighetto, G.P. Prete
                       INFN/LNL, Legnaro (PD), Italy
M. Bertocco
                       UNIPD, Padova (PD), Italy

 


 

SPES (Selective Production of Exotic Species) is an ISOL type RIB facility of the LNL-INFN at Italy dedicated to the production of neutron-rich radioactive nuclei by uranium fission. At the LNL, for the last four years, an off-line laboratory has been developed in order to study the target front-end test bench. The instrumentation devices are controlled using EPICS. A new flexible, easy to adapt, low cost and open solution for this control system is being tested. It consists on EPICS IOCs developed at the LNL which are based on the low cost computer board Raspberry Pi with custom-made expansion boards. The operating system is a modify version of Debian Linux running EPICS soft IOCs that communicates with the expansion board using home-made drivers. The expansion boards consist on multi-channel 16bits ADCs and DACs, digital inputs and outputs and stepper motor drivers. The idea is to have a distributed control system using customized IOC for controlling the instrumentation devices on the system as well as to read the information from the detectors using the EPICS channel access as communication protocol. This solution will be very cost effective and easy to customize.

 






Poster TUPPC053 [2.629 MB]
            
 


 



TUPPC054
A PLC-Based System for the Control of an Educational Observatory
691


 

V. Baldini, R. Cirami, I. Coretti, P. Di Marcantonio, S. Galeotta, G. Iafrate, M. Mannetta, P. Santin
                       INAF-OAT, Trieste, Italy

 


 

An educational project that aims to involve young students in astronomical observations has been developed in the last decade at the Basovizza branch station of the INAF-Astronomical Observatory of Trieste. The telescope used is a 14” reflector equipped with a robotic Paramount ME equatorial mount and placed in a non-automatic dome. The new-developing control system is based on Beckhoff PLC. The control system will mainly allow to remotely control the three-phase synchronous motor of the dome, the switching of the whole instrumentation and the park of the telescope. Thanks to the data coming from the weather sensor, the PLC will be able to ensure the safety of the instruments. A web interface is used for the communication between the user and the instrumentation. In this paper a detailed description of the whole PLC-based control system architecture will be presented.

 






Poster TUPPC054 [3.671 MB]
            
 


 



TUPPC055
Developing of the Pulse Motor Controller Electronics for Running under Weak Radiation Environment
695


 

M. Ishizuka, N. Araki, H. Kashima, H. Mukai
                       Hitachi Zosen, Osaka, Japan

 


 

Hitz Hitachi Zosen has developed new pulse motor controller. This controller which controls two axes per one controller implements high performance processor, pulse control device and peripheral interface. This controller has simply extensibility and various interface and realizes low price. We are able to operate the controller through Ethernet TCP/IP(or FLnet). Also, the controller can control max 16 axes. In addition, we want to drive the motor controller in optics hatch filled with weak radiation. If we can put the controller in optics hatch, wiring will become simple because of closed wiring in optics hatch . Therefore we have evaluated controller electronics running under weak radiation.

 






Poster TUPPC055 [0.700 MB]
            
 


 



TUPPC057
New Development of EPICS-based Data Acquisition System for Electron Cyclotron Emission Diagnostics in KSTAR Tokamak
699


 

T.G. Lee, K.D. Lee, S. Lee, W.R. Lee, M.K. Park
                       NFRI, Daejon, Republic of Korea

 


 

Korea Superconducting Tokamak Advanced Research (KSTAR) will be operated in the 6nd campaign in 2013 after achievement of first plasma in 2008. Many diagnostic devices have been installed for measuring the various plasma properties in the KSTAR tokamak during the campaigns. From the first campaign, a data acquisition system of Electron Cyclotron Emission (ECE) Heterodyne Radiometer (HR) has been operated to measure the radial profile of electron temperature. The DAQ system at the beginning was developed with a VME-form factor digitizer in Linux OS platform. However, this configuration had some limitations that it could not acquire over 100,000 samples per second due to its unstable operation during the campaigns. In order to overcome these weak points, a new ECE HR DAQ system is under development with a cPCI-form factor in Linux OS platform and the main control application will be developed based on EPICS framework like other control systems installed in KSTAR. Besides solving the described problems main advantages of the new ECE HR DAQ system are capabilities of calculating plasma electron temperature during plasma shot and displaying it in run-time.

 






Poster TUPPC057 [1.286 MB]
            
 


 



TUPPC058
Automation of Microbeam Focusing for X-Ray Micro-Experiments at the 4B Beamline of Pohang Light Source-II
703


 

K.H. Gil, H. J. Choi, J.Y. Huang, J.H. Lim
                       PAL, Pohang, Kyungbuk, Republic of Korea
C.W. Bark
                       Gachon University, Seongnam, Republic of Korea

 


 

The 4B beamline of the Pohang Light Source-II performs X-ray microdiffraction and microfluorescence experiments using X-ray microbeams. The microbeam has been focused down to FWHM sizes of less than 3 μm by manually adjusting the vertical and horizontal focusing mirrors of a K-B (Kirkpatrick-Baez) mirror system. In this research, a microbeam-focusing automation software was developed to automate the old complex and cumbersome process of beam focusing which may take about a day. The existing controllers of the K-B mirror system were replaced by products with communication functions and a motor-driving routine by means of proportional feedback control was constructed. Based on the routine and the outputs of two ionization chambers arranged in front and rear of the K-B mirror system, the automation software to perform every step of the beam focusing process was completed as LabVIEW applications. The developed automation software was applied to the 4B beamline and showed the performance of focusing an X-ray beam with a minimal size within an hour. This presentation introduces the details of the algorithms of the automation software and examines its performances.

 






Poster TUPPC058 [1.257 MB]
            
 


 



TUPPC059
EPICS Data Acquisition Device Support
707


 

V.A. Isaev, N. Claesson
                       Cosylab, Ljubljana, Slovenia
M. Pleško, K. Žagar
                       COBIK, Solkan, Slovenia

 


 

A large number of devices offer a similar kind of capabilities. For example, data acquisition all offer sampling at some rate. If each such device were to have a different interface, engineers using them would need to be familiar with each device specifically, inhibiting transfer of know-how from working with one device to another and increasing the chance of engineering errors due to a miscomprehension or incorrect assumptions. In the Nominal Device Model (NDM) model, we propose to standardize the EPICS interface of the analog and digital input and output devices, and image acquisition devices. The model describes an input/output device which can have digital or analog channels, where channels can be configured for output or input. Channels can be organized in groups that have common parameters. NDM is implemented as EPICS Nominal Device Support library (NDS). It provides a C++ interface to developers of device-specific drivers. NDS itself inherits well-known asynPortDriver. NDS hides from the developer all the complexity of the communication with asynDriver and allows to focus on the business logic of the device itself.

 






Poster TUPPC059 [0.371 MB]
            
 


 



TUPPC060
Implementation of Continuous Scans Used in Beamline Experiments at Alba Synchrotron
710


 

Z. Reszela, F. Becheri, G. Cuní, D.F.C. Fernández-Carreiras, J. Moldes, C. Pascual-Izarra
                       CELLS-ALBA Synchrotron, Cerdanyola del Vallès, Spain
T.M. Coutinho
                       ESRF, Grenoble, France

 


 

The Alba control system * is based on Sardana **, a software package implemented in Python, built on top of Tango *** and oriented to beamline and accelerator control and data acquisition. Sardana provides an advanced scan framework, which is commonly used in all the beamlines of Alba as well as other institutes. This framework provides standard macros and comprises various scanning modes: step, hybrid and software-continuous, however no hardware-continuous. The continuous scans speed up the data acquisition, making it a great asset for most experiments and due to time constraints, mandatory for a few of them. A continuous scan has been developed and installed in three beamlines where it reduced the time overheads of the step scans. Furthermore it could be easily adapted to any other experiment and will be used as a base for extending Sardana scan framework with the generic continuous scan capabilities. This article describes requirements, plan and implementation of the project as well as its results and possible improvements.
*"The design of the Alba Control System. […]" D. Fernández et al, ICALEPCS2011  **"Sardana, The Software for Building SCADAS […]" T.M. Coutinho et al, ICALEPCS2011 ***www.tango-controls.org

 






Poster TUPPC060 [13.352 MB]
            
 


 



TUPPC061
BL13-XALOC, MX experiments at Alba: Current Status and Ongoing Improvements
714


 

G. Cuní, J. Benach, D.F.C. Fernández-Carreiras, J. Juanhuix, C. Pascual-Izarra, Z. Reszela
                       CELLS-ALBA Synchrotron, Cerdanyola del Vallès, Spain
T.M. Coutinho
                       ESRF, Grenoble, France

 


 

BL13-XALOC is the only Macromolecular Crystallography (MX) beamline at the 3-GeV ALBA synchrotron. The control system is based on Tango * and Sardana **, which provides a powerful python-based environment for building and executing user-defined macros, a comprehensive access to the hardware, a standard Command Line Interface based on ipython, and a generic and customizable Graphical User Interface based on Taurus ***. Currently, the MX experiments are performed through panels that provide control to different beamline instrumentation. Users are able to collect diffraction data and solve crystal structures, and now it is time to improve the control system by combining the feedback from the users with the development of the second stage features: group all the interfaces (i.e. sample viewing system, automatic sample changer, fluorescence scans, and data collections) in a high-level application and implement new functionalities in order to provide a higher throughput experiment, with data collection strategies, automated data collections, and workflows. This article describes the current architecture of the XALOC control system, and the plan to implement the future improvements.
* http://www.tango-controls.org/  ** http://www.sardana-controls.org/ *** http://www.tango-controls.org/static/taurus/

 






Poster TUPPC061 [2.936 MB]
            
 


 



TUPPC062
High-Speed Data Acquisition of Sensor Signals for Physical Model Verification at CERN HiRadMat (SHC-DAQ)
718


 

C. Charrondière, M. Guinchard, S. Marques Dos Santos
                       CERN, Geneva, Switzerland

 


 

A high-speed data acquisition system was successfully developed and put into production in a harsh radiation environment in a couple of months to test new materials impacted by proton beams for future use in beam intercepting devices. A 4 MHz ADC with high impedance and low capacitance was used to digitize the data at a 2 MHz bandwidth. The system requirements were to design a full speed data streaming on a trigger during up to 30 ms and then reconfigure the hardware in less than 500 ms to perform a 100 Hz acquisition for 30 seconds. Experimental data were acquired, using LabVIEW real-time, relying on extensive embedded instrumentation (strain gauges and temperature sensors) and on acquisition boards hosted on a PXI crate. The data acquisition system has a dynamic range and sampling rate that are sufficient to acquire the very fast and intense shock waves generated by the impact. This presentation covers the requirements, the design, development and commissioning of the system. The overall performance, user experience and preliminary results will be reported.

 






Poster TUPPC062 [9.444 MB]
            
 


 



TUPPC063
Control and Monitoring of the Online Computer Farm for Offline Processing in LHCb
721


 

L.G. Cardoso, P. Charpentier, J. Closier, M. Frank, C. Gaspar, B. Jost, G. Liu, N. Neufeld
                       CERN, Geneva, Switzerland
O. Callot
                       LAL, Orsay, France

 


 

LHCb, one of the 4 experiments at the LHC accelerator at CERN, uses approximately 1500 PCs (averaging 12 cores each) for processing the High Level Trigger (HLT) during physics data taking. During periods when data acquisition is not required most of these PCs are idle. In these periods it is possible to profit from the unused processing capacity to run offline jobs, such as Monte Carlo simulation. The LHCb offline computing environment is based on LHCbDIRAC (Distributed Infrastructure with Remote Agent Control). In LHCbDIRAC, job agents are started on Worker Nodes, pull waiting tasks from the central WMS (Workload Management System) and process them on the available resources. A Control System was developed which is able to launch, control and monitor the job agents for the offline data processing on the HLT Farm. This control system is based on the existing Online System Control infrastructure, the PVSS SCADA and the FSM toolkit. It has been extensively used launching and monitoring 22.000+ agents simultaneously and more than 850.000 jobs have already been processed in the HLT Farm. This paper describes the deployment and experience with the Control System in the LHCb experiment.

 






Poster TUPPC063 [2.430 MB]
            
 


 



TUPPC064
Reusing the Knowledge from the LHC Experiments to Implement the NA62 Run Control
725


 

F. Varela, M. Gonzalez-Berges
                       CERN, Geneva, Switzerland
N. Lurkin
                       UCL, Louvain-la-Neuve, Belgium

 


 

NA62 is an experiment designed to measure very rare kaon decays at the CERN SPS planned to start operation in 2014. Until this date, several intermediate run periods have been scheduled to exercise and commission the different parts and subsystems of the detector. The Run Control system monitors and controls all processes and equipment involved in data-taking. This system is developed as a collaboration between the NA62 Experiment and the Industrial Controls and Engineering (EN-ICE) Group of the Engineering Department at CERN. In this paper, the contribution of EN-ICE to the NA62 Run Control project is summarized. EN-ICE has promoted the utilization of standardized control technologies and frameworks at CERN, which were originally developed for the controls of the LHC experiments. This approach has enabled to deliver a working system for the 2013 Technical Run that exceeded the initial requirements, in a very short time and with limited manpower.

 


 



TUPPC066
10 Years of Experiment Control at SLS Beam Lines: an Outlook to SwissFEL
729


 

J. Krempaský, U. Flechsig, B. Kalantari, X.Q. Wang
                       PSI, Villigen PSI, Switzerland
T. Mooney
                       ANL, Argonne, USA
M.L. Rivers
                       CARS, Argonne, Ilinois, USA

 


 

Today, after nearly 10 years of consolidated user operation at the Swiss Light Source (SLS) with up to 18 beam lines, we are looking back to briefly describe the success story based on EPICS controls toolkit and give an outlook towards the X-ray free-electron laser SwissFEL, the next challenging PSI project. We focus on SLS spectroscopy beam lines with experimental setups rigorously based on the SynApps "Positioner-Trigger-Detector" (PTD) anatomy [2]. We briefly describe the main beam line “Positioners” used inside the PTD concept. On the “Detector” side an increased effort is made to standardize the control within the areaDetector (AD) software package [3]. For the SwissFEL two detectors are envisaged: the Gotthard 1D and Jungfrau 2D pixel detectors, both built at PSI. Consistently with the PTD-anatomy, their control system framework based on the AD package is in preparation. In order to guarantee data acquisition with the SwissFEL nominal 100 Hz rate, the “Trigger” is interconnected with the SwissFEL timing system to guarantee shot-to-shot operation [4]. The AD plug-in concept allows significant data reduction; we believe this opens the doors towards on-line FEL experiments.
[1] Krempaský et al, ICALEPCS 2001  [2] www.aps.anl.gov/bcda/synApps/index.php  [3] M. Rivers, SRI 2009, Melbourne   [4] B. Kalantari et al, ICALEPCS 2011 

 


 



TUPPC067
A Distributed Remote Monitoring System for ISIS Sample Environment
733


 

M.R.W. North, G.L. Burgess
                       STFC/RAL/ISIS, Chilton, Didcot, Oxon, United Kingdom

 


 

The benefits of remote monitoring in industrial and manufacturing plants are well documented and equally applicable to scientific research facilities. This paper highlights the benefits of implementing a distributed monitoring system for sample environment equipment and instrumentation at the ISIS Neutron & Muon source facility. The upcoming implementation of an EPICS replacement for the existing beamline control system provides a timely opportunity to integrate operational monitoring and diagnostic capabilities with minimal overheads. The ISIS facility located at the Rutherford Appleton Laboratory UK is the most productive research centre of its type in the world supporting a national and international community of more than 2000 scientists using neutrons and muons for research into materials and life sciences.

 






Poster TUPPC067 [0.821 MB]
            
 


 



TUPPC069
ZEBRA: a Flexible Solution for Controlling Scanning Experiments
736


 

T.M. Cobb, Y.S. Chernousko, I.S. Uzun
                       Diamond, Oxfordshire, United Kingdom

 


 

This paper presents the ZEBRA product developed at Diamond Light Source. ZEBRA is a stand-alone event handling system with interfaces to multi-standard digital I/O signals (TTL, LVDS, PECL, NIM and Open Collector) and RS422 quadrature incremental encoder signals. Input events can be triggered by input signals, encoder position signals or repetitive time signals, and can be combined using logic gates in an FPGA to generate and output other events. The positions of all 4 encoders can be captured at the time of a given event and made available to the controlling system. All control and status is available through a serial protocol, so there is no dependency on a specific higher level control system. We have found it has applications on virtually all Diamond beamlines, from applications as simple as signal level shifting to, for example, using it for all continuous scanning experiments. The internal functionality is reconfigurable on the fly through the user interface and can be saved to static memory. It provides a flexible solution to interface different third party hardware (detectors and motion controllers) and to configure the required functionality as part of the experiment.

 






Poster TUPPC069 [2.909 MB]
            
 


 



TUPPC070
Detector Controls for the NOvA Experiment Using Acnet-in-a-Box
740


 

D.J. Nicklaus, L.R. Carmichael, D. Finstrom, B. Hendricks, CA. King, W.L. Marsh, R. Neswold, J.F. Patrick, J.G. Smedinghoff, J. You
                       Fermilab, Batavia, USA

 


 

In recent years, we have packaged the Fermilab accelerator control system, Acnet, so that other instances of it can be deployed independent of the Fermilab infrastructure. This encapsulated "Acnet-in-a-Box" is installed as the detector control system at the NOvA Far Detector. NOvA is a neutrino experiment using a beam of particles produced by the Fermilab accelerators. There are two NOvA detectors: a 330 ton ‘‘Near Detector'' on the Fermilab campus and a 14000 ton ‘‘Far Detector'' 735 km away. All key tiers and aspects of Acnet are available in the NOvA instantiation, including the central device database, java Open Access Clients, erlang front-ends, application consoles, synoptic displays, data logging, and state notifications. Acnet at NOvA is used for power-supply control, monitoring position and strain gauges, environmental control, PLC supervision, relay rack monitoring, and interacting with Epics PVs instrumenting the detector's avalanche photo-diodes. We discuss the challenges of maintaining a control system in a remote location, synchronizing updates between the instances, and improvements made to Acnet as a result of our NOvA experience.

 






Poster TUPPC070 [0.876 MB]
            
 


 



TUPPC071
Muon Ionization Cooling Experiment: Controls and Monitoring
743


 

P.M. Hanlet
                       IIT, Chicago, Illinois, USA

 


 

The Muon Ionization Cooling Experiment is a demonstration experiment to prove the feasibility of cooling a beam of muons for use in a Neutrino Factory and/or Muon Collider. The MICE cooling channel will produce a 10% reduction in beam emittance which will be measured with a 1% resolution, and this level of precision requires strict controls and monitoring of all experimental parameters to minimize systematic errors. The MICE Controls and Monitoring system is based on EPICS and integrates with the DAQ, data monitoring systems, a configuration database, and state machines for device operations. Run Control has been developed to ensure proper sequencing of equipment and use of system resources to protect data quality. State machines are used in test operations of cooling channel superconducting solenoids to set parameters for monitoring, alarms, and data archiving. A description of this system, its implementation and performance during both muon beam data collection and magnet training will be discussed.

 






Poster TUPPC071 [1.820 MB]
            
 


 



TUPPC072
Flexible Data Driven Experimental Data Analysis at the National Ignition Facility
747


 

A.D. Casey, R.C. Bettenhausen, E.J. Bond, R.N. Fallejo, M.S. Hutton, J.A. Liebman, A.A. Marsh, T. M. Pannell, S.M. Reisdorf, A.L. Warrick
                       LLNL, Livermore, California, USA

 


 

Funding: This work was performed under the auspices of the Lawrence Livermore National Security, LLC, (LLNS) under Contract No. DE-AC52-07NA27344. #LLNL-ABS-632532
After each target shot at the National Ignition Facility (NIF), scientists require data analysis within 30 minutes from ~50 diagnostic instrument systems. To meet this goal, NIF engineers created the Shot Data Analysis (SDA) Engine based on the Oracle Business Process Execution Language (BPEL) platform. While this provided for a very powerful and flexible analysis product, it still required engineers conversant in software development practices in order to create the configurations executed by the SDA engine. As more and more diagnostics were developed and the demand for analysis increased, the development staff was not able to keep pace. To solve this problem, the Data Systems team took the approach of creating a database table based scripting language that allows users to define an analysis configuration of inputs, input the data into standard processing algorithms and then store the outputs in a database. The creation of the Data Driven Engine (DDE) has substantially decreased the development time for new analysis and simplified maintenance of existing configurations. The architecture and functionality of the Data Driven Engine will be presented along with examples.

 






Poster TUPPC072 [1.150 MB]
            
 


 



TUPPC073
National Ignition Facility (NIF) Dilation X-ray Imager (DIXI) Diagnostic Instrumentation and Control System
751


 

J.R. Nelson, J. Ayers, M. A. Barrios Garcia, P.M. Bell, D.K. Bradley, G.W. Collins, B. Felker, S. Heerey, O.S. Jones, L.J. Lagin, S.R. Nagel, K.W. Piston, K. S. Raman, R.T. Shelton, R. F. Smith
                       LLNL, Livermore, California, USA
T. Chung, T. Hilsabeck, J. Kilkenny, B. Sammuli
                       GA, San Diego, California, USA
A.K.L. Dymoke-Bradshaw, J.D. Hares
                       Kentech Instruments Ltd., Wallingford, Oxfordshire, United Kingdom

 


 

Funding: * This work was performed under the auspices of the Lawrence Livermore National Security, LLC, (LLNS) under Contract No. DE-AC52-07NA27344. #LLNL-ABS-633832
X-ray cameras on inertial confinement fusion facilities can determine the implosion velocity and symmetry of NIF targets by recording the emission of X-rays from the target gated as a function of time. To capture targets that undergo ignition and thermonuclear burn, however, cameras with less than 10 picosecond shutter times are needed. A Collaboration between LLNL, General Atomics and Kentech Instruments has resulted in the design and construction of an X-ray camera which converts an X-ray image to an electron image, which is stretched, and then coupled to a conventional shuttered electron camera to meet this criteria. This talk discusses target diagnostic instrumentation and software used to control the DIXI diagnostic and seamlessly integrate it into the National Ignition Facility (NIF) Integrated Computer Control System (ICCS).

 






Poster TUPPC073 [3.443 MB]
            
 


 



TUPPC076
SNS Instrument Data Acquisition and Controls
755


 

S.M. Hartman
                       ORNL, Oak Ridge, Tennessee, USA

 


 

Funding: SNS is managed by UT-Battelle, LLC, under contract DE-AC05-00OR22725 for the U. S. Department of Energy.
The data acquisition (DAQ) and control systems for the neutron beam line instruments at the Spallation Neutron Source (SNS) are undergoing upgrades addressing three critical areas: data throughput and data handling from DAQ to data analysis, instrument controls including user interface and experiment automation, and the low-level electronics for DAQ and timing. This paper will outline the status of the upgrades and will address some of the challenges in implementing fundamental upgrades to an operating facility concurrent with commissioning of existing beam lines and construction of new beam lines.

 


 



TUPPC077
Experiment Automation with a Robot Arm Using the Liquids Reflectometer Instrument at the Spallation Neutron Source
759


 

B. Vacaliuc, G.C. Greene, A.A. Parizzi, M. Sundaram
                       ORNL RAD, Oak Ridge, Tennessee, USA
J.F. Ankner, J.F. Browning, C.E. Halbert, M.C. Hoffmann, P. Zolnierczuk
                       ORNL, Oak Ridge, Tennessee, USA

 


 

Funding: U.S. Government under contract DE-AC05-00OR22725 with UT-Battelle, LLC, which manages the Oak Ridge National Laboratory.
The Liquids Reflectometer instrument installed at the Spallation Neutron Source (SNS) enables observations of chemical kinetics, solid-state reactions and phase-transitions of thin film materials at both solid and liquid surfaces. Effective measurement of these behaviors requires each sample to be calibrated dynamically using the neutron beam and the data acquisition system in a feedback loop. Since the SNS is an intense neutron source, the time needed to perform the measurement can be the same as the alignment process, leading to a labor-intensive operation that is exhausting to users. An update to the instrument control system, completed in March 2013, implemented the key features of automated sample alignment and robot-driven sample management, allowing for unattended operation over extended periods, lasting as long as 20 hours. We present a case study of the effort, detailing the mechanical, electrical and software modifications that were made as well as the lessons learned during the integration, verification and testing process.

 






Poster TUPPC077 [17.799 MB]
            
 


 



TUPPC078
First EPICS/CSS Based Instrument Control and Acquisition System at ORNL
763


 

X. Geng, X.H. Chen, K.-U. Kasemir
                       ORNL, Oak Ridge, Tennessee, USA

 


 

Funding: SNS is managed by UT-Battelle, LLC, under contract DE-AC05-00OR22725 for the U.S. Department of Energy
The neutron imaging prototype beamline (CG-1D) at the Oak Ridge National Laboratory High Flux Isotope Reactor (HFIR) is used for many different applications necessitating a flexible and stable instrument control system. Beamline scientists expect a robust data acquisition system. They need a clear and concise user interface that allows them to both configure an experiment and to monitor an ongoing experiment run. Idle time between acquiring consecutive images must be minimized. To achieve these goals, we implement a system based upon EPICS, a newly developed CSS scan system, and CSS BOY. This paper presents the system architecture and possible future plans.

 






Poster TUPPC078 [6.846 MB]
            
 


 



TUPPC081
IcePAP: An Advanced Motor Controller for Scientific Applications in Large User Facilities
766


 

N. Janvier, J.M. Clement, P. Fajardo
                       ESRF, Grenoble, France
G. Cuní
                       CELLS-ALBA Synchrotron, Cerdanyola del Vallès, Spain

 


 

Synchrotron radiation facilities and in particular large hard X-ray sources such as the ESRF are equipped with thousands of motorized position actuators. Combining all the functional needs found in those facilities with the implications related to personnel resources, expertise and cost makes the choice of motor controllers a strategic matter. Most of the large facilities adopt strategies based on the use of off-the-shelf devices packaged using standard interfaces. As this approach implies severe compromises, the ESRF decided to address the development of IcePAP, a motor controller designed for applications in a scientific environment. It optimizes functionality, performance, ease of deployment, level of standardization and cost. This device is adopted as standard and is widely used at the beamlines and accelerators of ESRF and ALBA. This paper provides details on the architecture and technical characteristics of IcePAP as well as examples on how it implements advanced features. It also presents ongoing and foreseen improvements as well as introduces the outline of an emerging collaboration aimed at further development of the system making it available to other research labs.

 






Poster TUPPC081 [0.615 MB]
            
 


 



TUPPC082
DSP Design Using System Generator
770


 

J.M. Koch
                       ESRF, Grenoble, France

 


 

When designing a real time control system, a fast data transfer between the different pieces of hardware must be guaranteed since synchronization and determinism have to be respected. One efficient solution to cope with these constraints is to embed the data collection, the signal-processing and the driving of the acting devices in FPGAs. Although this solution imposes that the whole design is being developed for an FPGA, in pure hardware, it is possible to open the part dedicated to the signal processing to non HDL (Hardware Description Language) specialists; the choice has been made here to develop this part under System Generator, in Simulink. Another challenge in such system design is the integration of real time models on already pre-configured hardware platforms. This paper describes with few examples how to interface such hardware with HDL System Generator control systems blocks. The advantages of Simulink for the simulation phase of the design as well as the possibility to introduce models dedicated to the tests are also presented.

 






Poster TUPPC082 [0.924 MB]
            
 


 



TUPPC083
FPGA Implementation of a Digital Constant Fraction for Fast Timing Studies in the Picosecond Range
774


 

P. Mutti, J. Ratel, F. Rey, E. Ruiz-Martinez
                       ILL, Grenoble, France

 


 

Thermal or cold neutron capture on different fission systems is an excellent method to produce a variety of very neutron-rich nuclei. Since neutrons at these energies bring in the reaction just enough energy to produce fission, the fragments remain neutron-rich due to the negligible neutron evaporation thus allowing detailed nuclear structure studies. In 2012 and 2013 a combination of EXOGAM, GASP and Lohengrin germanium detectors has been installed at the PF1B cold neutron beam of the Institut Laue-Langevin. The present paper describes the digital acquisition system used to collect information on all gamma rays emitted by the decaying nuclei. Data have been acquired in a trigger-less mode to preserve a maximum of information for further off-line treatment with a total throughput of about 10 MByte/sec. Special emphasis is devoted to the FPGA implementation of an on-line digital constant fraction algorithm allowing fast timing studies in the pico second range.

 






Poster TUPPC083 [9.928 MB]
            
 


 



TUPPC086
Electronics Developments for High Speed Data Throughput and Processing
778


 

C. Youngman, B. Fernandes, P. Gessler
                       XFEL. EU, Hamburg, Germany
J. Coughlan
                       STFC/RAL, Chilton, Didcot, Oxon, United Kingdom
E. Motuk
                       UCL, London, United Kingdom
M. Zimmer
                       DESY, Hamburg, Germany

 


 

Funding: The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007-2013) under grant agreement No. 283745
The European XFEL DAQ system has to acquire and process data in short bursts every 100ms. Bursts lasts for 600us and contain a maximum of 2700 x-ray pulses with a repetition rate of 4.5MHz which have to be captured and processed before the next burst starts. This time structure defines the boundary conditions for almost all diagnostic and detector related DAQ electronics required and currently being developed for start of operation in fall 2015. Standards used in the electronics developments are: MicroTCA.4 and AdvancedTCA crates, use of FPGAs for data processing, transfer to backend systems via 10Gbps (SFP+) links, and feedback information transfer using 3.125Gbps (SFP) links. Electronics being developed in-house or in collaboration with external institutes and companies include: a Train Builder ATCA blade for assembling and processing data of large-area image detectors, a VETO MTCA.4 development for evaluating pulse information and distributing a trigger decision to detector front-end ASICs and FPGAs with low-latency, a MTCA.4 digitizer module, interface boards for timing and similar synchronization information, etc.

 






Poster TUPPC086 [0.983 MB]
            
 


 



TUPPC087
High Level FPGA Programming Framework Based on Simulink
782


 

B. Fernandes, P. Gessler, C. Youngman
                       XFEL. EU, Hamburg, Germany

 


 

Funding: The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007-2013) under grant agreement No 283745.
Modern diagnostic and detector related data acquisition and processing hardware are increasingly being implemented with Field Programmable Gate Array (FPGA) technology. The level of flexibility allows for simpler hardware solutions together with the ability to implement functions during the firmware programming phase. The technology is also becoming more relevant in data processing, allowing for reduction and filtering to be done at the hardware level together with implementation of low-latency feedback systems. However, this flexibility and possibilities require a significant amount of design, programming, simulation and testing work usually done by FPGA experts. A high-level FPGA programming framework is currently under development at the European XFEL in collaboration with the Oxford University within the EU CRISP project. This framework allows for people unfamiliar with FPGA programming to develop and simulate complete algorithms and programs within the MathWorks Simulink graphical tool with real FPGA precision. Modules within the framework allow for simple code reuse by compiling them into libraries, which can be deployed to other boards or FPGAs.

 






Poster TUPPC087 [0.813 MB]
            
 


 



TUPPC088
Development of MicroTCA-based Image Processing System at SPring-8
786


 

A. Kiyomichi, M. Masaki, T. Masuda, S. Ueda
                       JASRI/SPring-8, Hyogo-ken, Japan

 


 

In SPring-8, various CCD cameras have been utilized for electron beam diagnostics of accelerators and x-ray imaging experiments. PC-based image processing systems are mainly used for the CCD cameras with Cameralink I/F. We have developed a new image processing system based on MicroTCA platform, which has an advantage over PC in robustness and scalability due to its hot-swappable modular architecture. In order to reduce development cost and time, the new system is built with COTS products including a user-configurable Spartan6 AMC with an FMC slot and a Cameralink FMC. The Cameralink FPGA core is newly developed in compliance with the AXI4 open-bus to enhance reusability. The MicroTCA system will be first applied to upgrade of the two-dimensional synchrotron radiation interferometer[1] operating at the SPring-8 storage ring. The sizes and tilt angle of a transverse electron beam profile with elliptical Gaussian distribution are extracted from an observed 2D-interferogram. A dedicated processor AMC (PrAMC) that communicates with the primary PrAMC via backplane is added for fast 2D-fitting calculation to achieve real-time beam profile monitoring during the storage ring operation.
[1] "Two-dimensional visible synchrotron light interferometry for transverse beam-profile measurement at the SPring-8 storage ring", M.Masaki and S.Takano, J. Synchrotron Rad. 10, 295 (2003).

 






Poster TUPPC088 [4.372 MB]
            
 


 



TUPPC089
Upgrade of the Power Supply Interface Controller Module for SuperKEKB
790


 

T.T. Nakamura, A. Akiyama, K. Furukawa, M. Iwasaki, H. Kaji, S. Sasaki
                       KEK, Ibaraki, Japan

 


 

There were more than 2500 magnet power supplies for KEKB storage rings and injection beam transport lines. For the remote control of such a large number of power supplies, we have developed the Power Supply Interface Controller Module (PSICM), which is plugged into each power supply. It has a microprocessor, ARCNET interface, trigger signal input interface, and parallel interface to the power supply. The PSICM is not only an interface card but also controls synchronous operation of the multiple power supplies with an arbitrary tracking curve. For SuperKEKB, the upgrade of KEKB, most of the existing power supplies continues while handreds of new power suplies are also installed. Although the PSICMs have worked without serious problem for 12 years, it seems too hard to keep maintenance for the next decade because of the discontinued parts. Thus we have developed the upgraded version of the PSICM. The new PSICM has the fully backward compatible interface to the power supply. The enhanced features are high speed ARCNET communication and redundant trigger signals. The design and the status of the upgraded PSICM are presented.

 






Poster TUPPC089 [1.516 MB]
            
 


 



TUPPC090
Digital Control System of High Extensibility for KAGRA
794


 

H. Kashima, N. Araki, M. Ishizuka, T. Masuoka, H. Mukai
                       Hitachi Zosen, Osaka, Japan
O. Miyakawa
                       ICRR, Chiba, Japan

 


 

KAGRA is the large scale cryogenic gravitational wave telescope project in Japan which is developed and constructed by ICRR. of The University of Tokyo. Hitz Hitachi Zosen produced PCI Express I/O chassis and the anti-aliasing/anti-imaging filter board for KAGRA digital control system. These products are very important for KAGRA interferometer from the point of view of low noise operations. This paper reports the performance of these products.

 






Poster TUPPC090 [0.487 MB]
            
 


 



TUPPC094
Em# Project. Improvement of Low Current Measurements at Alba Synchrotron
798


 

X. Serra-Gallifa, J.A. Avila-Abellan, J.J. Jamroz, O. Matilla
                       CELLS-ALBA Synchrotron, Cerdanyola del Vallès, Spain

 


 

After two years with 50 four-channels electrometer measurement units working successfully at Alba beamlines, new features implementation have forced a complete instrument architecture change. This new equipment is taking advantage of the targets achieved as the remarkable low noise in the current amplifier stage and implements new features currently not available in the market. First an embedded 18 bits SAR ADC able to work under up to 500V biasing has been implemented looking for the highest possible accuracy. The data stream is analysed by a flexible data processing based on a FPGA which is able to execute sample-by-sample real-time calculation aimed to be applied in experiments as the current normalization absorption between two channel acquisitions; being able to optimize the SNR of an absorption spectrum. The equipment is oriented from the design stage to be integrated in continuous scans setups, implementing low level timestamp compatible with multiple clock sources standards using an SFP port. This port could also be used in the future to integrate XBPM measures into the FOFB network for the accelerator beam position correction.

 






Poster TUPPC094 [0.545 MB]
            
 


 



TUPPC095
Low Cost FFT Scope using LabVIEW cRIO and FPGA
801


 

O.O. Andreassen, L. Arnaudon, I.T. Matasaho, A. Rijllart
                       CERN, Geneva, Switzerland

 


 

At CERN, many digitizers and scopes are starting to age and should be replaced. Much of the equipment is custom made or not available on the market anymore. Replacing this equipment with the equivalent of today would either be time consuming or expensive. This paper looks at the pros and cons of using COTS systems like NI-cRIO and NI-PXIe and their FPGA capabilities as flexible instruments, replacing costly spectrum analyzers and older scopes. It adds some insight on what had to be done to integrate and deploy the equipment in the unique CERN infrastructure, and the added value of having a fully customizable platform, that makes it possible to stream, store and align the data without any additional equipment.

 






Poster TUPPC095 [5.250 MB]
            
 


 



TUPPC096
Migration from WorldFIP to a Low-Cost Ethernet Fieldbus for Power Converter Control at CERN
805


 

S.T. Page, Q. King, H. Lebreton, P.F. Semanaz
                       CERN, Geneva, Switzerland

 


 

Power converter control in the LHC uses embedded computers called Function Generator/Controllers (FGCs) which are connected to WorldFIP fieldbuses around the accelerator ring. The FGCs are integrated into the accelerator control system by x86 gateway front-end systems running Linux. With the LHC now operational, attention has turned to the renovation of older control systems as well as a new installation for Linac 4. A new generation of FGC is being deployed to meet the needs of these cycling accelerators. As WorldFIP is very limited in data rate and is unlikely to undergo further development, it was decided to base future installations upon an Ethernet fieldbus with standard switches and interface chipsets in both the FGCs and gateways. The FGC communications protocol that runs over WorldFIP in the LHC was adapted to work over raw Ethernet, with the aim to have a simple solution that will easily allow the same devices to operate with either type of interface. This paper describes the evolution of FGC communications from WorldFIP to dedicated Ethernet networks and presents the results of initial tests, diagnostic tools and how real-time power converter control is achieved.

 






Poster TUPPC096 [1.250 MB]
            
 


 



TUPPC098
Advanced Light Source Control System Upgrade – Intelligent Local Controller Replacement
809


 

W.E. Norum, R.E. Lellinger, G.J. Portmann
                       LBNL, Berkeley, California, USA

 


 

Funding: Work supported by the U.S. Department of Energy under Contract No. DE-AC02-05CH11231
As part of the control system upgrade at the Advanced Light Source (ALS) the existing intelligent local controller (ILC) modules have been replaced. These remote input/output modules provide real-time updates of control setpoints and monitored values. This paper describes the 'ILC Replacement Modules' which have been developed to take on the duties of the existing modules. The new modules use a 100BaseT network connection to communicate with the ALS Experimental Physics and Industrial Control System (EPICS) and are based on a commercial FPGA evaluation board running a microcontroller-like application. In addition to providing remote ana log and digital input/output points the replacement modules also provide some rudimentary logic operations, analog slew rate limiting and accurate time stamping of acquired data. Results of extensive performance testing and experience gained now that the modules have been in service for several months are presented.

 


 



TUPPC100
Recent Changes to Beamline Software at the Canadian Light Source
813


 

G. Wright, D. Beauregard, R. Berg, G. Black, D.K. Chevrier, R. Igarashi, E. D. Matias, C.D. Miller
                       CLS, Saskatoon, Saskatchewan, Canada

 


 

The Canadian Light Source has ongoing work to improve the user interfaces at the beamlines. Much of the direction has made use of Qt and EPICS, using both C++ and Python in providing applications. Continuing work on the underlying data acquisition and visualization tools provides a commonality for both development and operation, and provisions for extending tools allow flexibility in types of experiments being run.

 






Poster TUPPC100 [1.864 MB]
            
 


 



TUPPC101
Scaling of EPICS edm Display Pages at ISAC
816


 

R. Keitel
                       TRIUMF, Canada's National Laboratory for Particle and Nuclear Physics, Vancouver, Canada

 


 

The EPICS-based control system of the ISAC facility at TRIUMF uses the edm display editor / display manager to create and render the Operator interface displays. edm displays are expressed in pixel coordinates and edm does not scale the display page when a window is re-sized. A simple scheme was implemented to allow operators to switch page magnifications using a set of pre-selected scaling factors. Possible extensions of the scheme and its limitations will be discussed.

 






Poster TUPPC101 [1.067 MB]
            
 


 



TUPPC102
User Interfaces for the Spiral2 Machine Protection System
818


 

L. Philippe, P. Gillette, G. Normand
                       GANIL, Caen, France

 


 

Spiral2 accelerator is designed to accelerate protons, deuterons, ions with a power from hundreds of Watts to 200kW. Therefore, it is important to monitor and anticipate beam losses to maintain equipment integrities by triggering beam cuts when beam losses or equipment malfunctions are detected; the MPS (Machine Protection System) is in charge of this function. The MPS has also to monitor and limit activations but this part is not addressed here. Linked to the MPS, five human machine interfaces will be provided. The first, “MPS” lets operators and accelerator engineers monitor MPS states, alarms and tune some beam losses thresholds. The second “beam power rise” defines successive steps to reach the desired beam power. Then, “interlock” is a synoptic to control beam stops state and defaults; the “beam losses” one displays beam losses, currents and efficiencies along the accelerator. Finally, “beam structure” lets users interact with the timing system by controlling the temporal structure to obtain a specific duty cycle according to the beam power constraints. In this paper, we introduce these human machine interfaces, their interactions and the method used for software development.

 






Poster TUPPC102 [1.142 MB]
            
 


 



TUPPC106
Development of a Web-based Shift Reporting Tool for Accelerator Operation at the Heidelberg Ion Beam Therapy Center
822


 

K. Höppner, R. Cee, M. Galonska, Th. Haberer, J.M. Mosthaf, A. Peters, S. Scheloske
                       HIT, Heidelberg, Germany

 


 

The HIT (Heidelberg Ion Therapy) center is the first dedicated European accelerator facility for cancer therapy using both carbon ions and protons, located at the university hospital in Heidelberg. It provides three fully operational therapy treatment rooms, two with fixed beam exit and a gantry. We are currently developing a web based reporting tool for accelerator operations. Since medical treatment requires a high level of quality assurance, a detailed reporting on beam quality, device failures and technical problems is even more needed than in accelerator operations for science. The reporting tools will allow the operators to create their shift reports with support from automatically derived data, i.e. by providing pre-filled forms based on data from the Oracle database that is part of the proprietary accelerator control system. The reporting tool is based on the Python-powered CherryPy web framework, using SQLAlchemy for object relational mapping. The HTML pages are generated from templates, enriched with jQuery to provide a desktop-like usability. We will report on the system architecture of the tool and the current status, and show screenshots of the user interface.
[1] Th. Haberer et al., “The Heidelberg Ion Therapy Center”, Rad. & Onc.,

 


 



TUPPC108
Using Web Syndication for Flexible Remote Monitoring
825


 

O. Pinazza
                       INFN-Bologna, Bologna, Italy
A. Augustinus, P.M. Bond, P.Ch. Chochula, M. Lechman, P. Rosinský
                       CERN, Geneva, Switzerland
A.N. Kurepin
                       RAS/INR, Moscow, Russia

 


 

With the experience gained in the first years of running the ALICE apparatus we have identified the need of collecting and aggregating different data to be displayed to the user in a simplified, personalized and clear way. The data comes from different sources in several formats, can contain data, text, pictures or can simply be a link to an extended content. This paper will describe the idea to design a light and flexible infrastructure, to aggregate information produced in different systems and offer them to the readers. In this model, a reader is presented with the information relevant to him, without being obliged to browse through different systems. The project consists of data production, collection and syndication, and is being developed in parallel with more traditional monitoring interfaces, with the aim of offering the ALICE users an alternative and convenient way to stay updated about their preferred systems even when they are far from the experiment.

 






Poster TUPPC108 [1.301 MB]
            
 


 



TUPPC109
MacspeechX.py Module and Its Use in an Accelerator Control System
829


 

N. Yamamoto
                       KEK, Ibaraki, Japan

 


 

macspeechX.py is a Python module to accels speech systehsis library on MacOSX. This module have been used in the vocal alert system in KEKB and J-PARC accelrator cotrol system. Recent upgrade of this module allow us to handle non-English lanugage, such as Japanse, through this module. Implementation detail will be presented as an example of Python program accessing system library.

 


 



TUPPC110
Operator Intervention System for Remote Accelerator Diagnostics and Support
832


 

A. Uchiyama
                       Sokendai, Ibaraki, Japan
K. Furukawa
                       KEK, Ibaraki, Japan
Y. Higurashi
                       RIKEN Nishina Center, Wako, Japan

 


 

In a large experimental physics project such as ITER and LHC, the project has managed by an international collaboration. Similarly, ILC (International Linear Collider) as next generation project will be started by a collaboration of many institutes from three regions. After the collaborative construction, any collaborators except a host country will need to have some methods for remote maintenances by control and monitoring of devices. For example, the method can be provided by connecting to the control system network via WAN from their own countries. On the other hand, the remote operation of an accelerator via WAN has some issues from a practical application standpoint. One of the issues is that the accelerator has both experimental device and radiation generator characteristics. Additionally, after miss operation in the remote control, it will cause breakdown immediately. For this reason, we plan to implement the operator intervening system for remote accelerator diagnostics and support, and then it will solve the issues of difference of between the local control room and other locations. In this paper, we report the system concept, the development status, and the future plan.

 






Poster TUPPC110 [7.215 MB]
            
 


 



TUPPC111
Online Status and Settings Monitoring for the LHC Collimators
836


 

G. Valentino
                       University of Malta, Information and Communication Technology, Msida, Malta
R.W. Aßmann, D. Jacquet, S. Redaelli, E. Veyrunes
                       CERN, Geneva, Switzerland

 


 

The Large Hadron Collider is equipped with 100 movable collimators. The LHC collimator control system is responsible for the accurate synchronization of around 400 axes of motion at the microsecond level, and with the precision of a few micrometres. The status and settings of the collimators can be monitored by three displays in the CERN Control Center, each providing a different viewpoint onto the system and a different level of abstraction, such as the positions in mm or beam size units. Any errors and warnings are also displayed. In this paper, the display operation is described, as well as the interaction that occurs when an operator is required to identify and understand an error in the collimator settings.

 






Poster TUPPC111 [2.260 MB]
            
 


 



TUPPC112
GeoSynoptic Panel
840


 

Ł. Żytniak, C.J. Bocchetta, P.P. Goryl, P. Pamula, A.I. Wawrzyniak, M. Zając
                       Solaris, Kraków, Poland
V.H. Hardion, D.P. Spruce
                       MAX-lab, Lund, Sweden

 


 

Funding: Synchrotron Radiation Centre SOLARIS at Jagiellonian University ul. Gronostajowa 7/P-1.6 30-387 Kraków Poland
Solaris is a third generation Polish Synchrotron under construction at the Jagiellonian University in Kraków. Furthermore, National Synchrotron Radiation Center is member of the Tango Collaboration. The project is based on the 1.5 GeV storage ring being at the simultaneously built for the MAX IV project in Lund, Sweden. The Solaris project is a prime example of the benefits of use EU regional development funds and sharing of knowledge and resources for the rapid establishment of a national research infrastructure. The Solaris develops highly customizable and adaptable application called the GeoSynoptic Panel. Main goal of the GeoSynoptic Panel is to provide a graphical map of devices based on information stored in the Tango database. It is achieved by providing additional device/class properties which describe location and graphical components (such as icons and particular GUI window) related to a particular device or class . The application is expected to reduce time needed for preparation of synoptic applications for each individual (part of) machines or subsystems and to reduce effort related to debugging and change management.

 






Poster TUPPC112 [19.249 MB]
            
 


 



TUPPC115
Hierarchies of Alarms for Large Distributed Systems
844


 

M. Boccioli, M. Gonzalez-Berges, V. Martos
                       CERN, Geneva, Switzerland
O. Holme
                       ETH, Zurich, Switzerland

 


 

The control systems of most of the infrastructure at CERN makes use of the SCADA package WinCC OA by ETM, including successful projects to control large scale systems (i.e. the LHC accelerator and associated experiments). Each of these systems features up to 150 supervisory computers and several millions of parameters. To handle such large systems, the control topologies are designed in a hierarchical way (i.e. sensor, module, detector, experiment) with the main goal of supervising a complete installation with a single person from a central user interface. One of the key features to achieve this is alarm management (generation, handling, storage, reporting). Although most critical systems include automatic reactions to faults, alarms are fundamental for intervention and diagnostics. Since one installation can have up to 250k alarms defined, a major failure may create an avalanche of alarms that is difficult for an operator to interpret. Missing important alarms may lead to downtime or to danger for the equipment. The paper presents the developments made in recent years on WinCC OA to work with large hierarchies of alarms and to present summarized information to the operators.

 


 



TUPPC116
Cheburashka: A Tool for Consistent Memory Map Configuration Across Hardware and Software
848


 

A. Rey, A.C. Butterworth, F. Dubouchet, M. Jaussi, T.E. Levens, J.C. Molendijk, A.V. Pashnin
                       CERN, Geneva, Switzerland

 


 

The memory map of a hardware module is defined by the designer at the moment when the firmware is specified. It is then used by software developers to define device drivers and front-end software classes. Maintaining consistency between hardware and its software is critical. In addition, the manual process of writing VHDL firmware on one side and the C++ software on the other is labour-intensive and error-prone. Cheburashka* is a software tool which eases this process. From a unique declaration of the memory map, created using the tool’s graphical editor, it allows to generate the memory map VHDL package, the Linux device driver configuration for the front-end computer, and a FESA** class for debugging. An additional tool, GENA, is being used to automatically create all required VHDL code to build the associated register control block. These tools are now used by the hardware and software teams for the design of all new interfaces from FPGAs to VME or on-board DSPs in the context of the extensive program of development and renovation being undertaken in the CERN injector chain during LS1***. Several VME modules and their software have already been deployed and used in the SPS.
(*) Cheburashka is developed in the RF group at CERN  (**)FESA is an acronym for Front End Software Architecture, developped at CERN (***)LS1 : LHC Long Shutdown 1, from 2013 to 2014

 


 



TUPPC117
Unifying Data Diversity and Conversion to Common Engineering Analysis Tools
852


 

H. Reymond, O.O. Andreassen, C. Charrondière, M.F. Gomez De La Cruz, A. Rijllart
                       CERN, Geneva, Switzerland

 


 

The large variety of systems for the measurements of insulation, conductivity, RRR, quench performance, etc. installed at CERN’s superconducting magnet test facility generates a diversity of data formats. This mixture causes problems when the measurements need to be correlated. Each measurement application has a dedicated data analysis tool used to validate its results, but there are no generic bridge between the applications that facilitates cross analysis of mixed data and data types. Since the LHC start-up, the superconducting magnet test facility hosts new R&D measurements on a multitude of superconducting components. These results are analysed by international collaborators, which triggered a greater need to access the raw data from many typical engineering and analysis tools, such as MATLAB®, Mathcad®, DIAdem™, Excel™… This paper describes the technical solutions developed for the data formats unification and reviews the present status.

 






Poster TUPPC117 [11.140 MB]
            
 


 



TUPPC119
Exchange of Crucial Information between Accelerator Operation, Equipment Groups and Technical Infrastructure at CERN
856


 

I. Laugier, P. Sollander
                       CERN, Geneva, Switzerland

 


 

During CERN accelerator operation, a large number of events, related to accelerator operation and management of technical infrastructure, occur with different criticality. All these events are detected, diagnosed and managed by the Technical Infrastructure service (TI) in the CERN Control Centre (CCC); equipment groups concerned have to solve the problem with a minimal impact on accelerator operation. A new database structure and new interfaces have to be implemented to share information received by TI, to improve communication between the control room and equipment groups, to help post-mortem studies and to correlate events with accelerator operation incidents. Different tools like alarm screens, logbooks, maintenance plans and work orders exist and are in use today. A project was initiated with the goal to integrate and standardize information in a common repository to be used by the different stakeholders through dedicated user interfaces.

 






Poster TUPPC119 [10.469 MB]
            
 


 



TUPPC120
LHC Collimator Alignment Operational Tool
860


 

G. Valentino, R.W. Aßmann, S. Redaelli
                       CERN, Geneva, Switzerland
N.J. Sammut
                       University of Malta, Information and Communication Technology, Msida, Malta

 


 

Beam-based LHC collimator alignment is necessary to determine the beam centers and beam sizes at the collimator locations for various machine configurations. Fast and automatic alignment is provided through an operational tool has been developed for use in the CERN Control Center, which is described in this paper. The tool is implemented as a Java application, and acquires beam loss and collimator position data from the hardware through a middleware layer. The user interface is designed to allow for a quick transition from application start up, to selecting the required collimators for alignment and configuring the alignment parameters. The measured beam centers and sizes are then logged and displayed in different forms to help the user set up the system.

 






Poster TUPPC120 [2.464 MB]
            
 


 



TUPPC121
caQtDM, an EPICS Display Manager Based on Qt
864


 

A.C. Mezger
                       PSI, Villigen PSI, Switzerland

 


 

At the Paul Scherrer Institut (PSI) the display manager MEDM was used until recently for the synoptic displays at all our facilities,  not only for EPICS but also for another, in-house built control system ACS. However MEDM is based on MOTIF and Xt/X11, systems/libraries that  are starting to age. Moreover MEDM is difficult to extend with new entities. Therefore a new tool has been developed based on Qt. This  reproduces the functionality of MEDM and is now in use at several facilities. As Qt is supported on several platforms this tool will also  format using the parser tool adl2ui. These were then edited further with the Qt-Designer and displayed with the new Qt-Manager caQtDM.  The integration of new entities into the Qt designer and therefore into the Qt based applications is very easy, so that the system can  easily be enhanced with new widgets. New features needed for our facility were implemented. The caQtDM application uses a C++ class to  perform the data acquisition and display; this class can also be integrated into other applications.

 






Slides TUPPC121 [1.024 MB]
            
 


 



TUPPC122
Progress of the TPS Control Applications Development
867


 

Y.-S. Cheng, J. Chen, P.C. Chiu, K.T. Hsu, C.H. Huang, C.H. Kuo, C.Y. Liao
                       NSRRC, Hsinchu, Taiwan

 


 

The TPS (Taiwan Photon Source) is the latest generation 3 GeV synchrotron light source which is in installation phase. Commissioning is estimated in 2014. The EPICS is adopted as control system framework for the TPS. The various EPICS IOCs have implemented for each subsystem at this moment. Development and integration of specific control operation interfaces are in progress. The operation interfaces mainly include the function of setting, reading, save, restore and etc. Development of high level applications which are depended upon properties of each subsystem is on-going. The archive database system and its browser toolkits gradually have been established and tested. The Web based operation interfaces and broadcasting are also created for observing the machine status. The efforts will be summarized at this report.

 






Poster TUPPC122 [2.054 MB]
            
 


 



TUPPC123
User Interfaces Development of Imaging Diagnostic Devices for the Taiwan Photon Source
871


 

C.Y. Liao, Y.-S. Cheng, K.T. Hsu, C.H. Kuo, C.Y. Wu
                       NSRRC, Hsinchu, Taiwan

 


 

Taiwan Photon Source (TPS) is a 3 GeV synchrotron light source which is being construction at campus of National Synchrotron Radiation Research Center (NSRRC) in Taiwan. Many diagnostic devices are used for the implementation and will be deployed to assist commissioning and operating the TPS. The imaging diagnostics devices, includes screen monitor (SM), streak camera (SC), and intensified CCD (ICCD) are used and its user interfaces are plan to develop. Control of these applications is centered around EPICS IOC. The windows OS based system, such as SC and ICCD, are controlled respectively through the Matlab (combined with LabCA module) and LabVIEW (combined with DSC module) tools and share the data as EPICS PVs. The main user interfaces and data analysis are constructed by Matlab GUIDE toolbox. The progress of the plans will be summarized in this report.

 






Poster TUPPC123 [1.518 MB]
            
 


 



TUPPC124
Distributed Network Monitoring Made Easy - An Application for Accelerator Control System Process Monitoring
875


 

C.E. Peters, M.A. Power
                       ANL, Argonne, USA

 


 

Funding: This work was supported by the U.S. Department of Energy, Office of Nuclear Physics, under Contract No. DE-AC02-06CH11357.
As the complexity and scope of distributed control systems increase, so does the need for an ever increasing level of automated process monitoring. The goal of this paper is to demonstrate one method whereby the SNMP protocol combined with open-source management tools can be quickly leveraged to gain critical insight into any complex computing system. Specifically, we introduce an automated, fully customizable, web-based remote monitoring solution which has been implemented at the Argonne Tandem Linac Accelerator System (ATLAS). This collection of tools is not limited to only monitoring network infrastructure devices, but also to monitor critical processes running on any remote system. The tools and techniques used are typically available pre-installed or are available via download on several standard operating systems, and in most cases require only a small amount of configuration out of the box. High level logging, level-checking, alarming, notification and reporting is accomplished with the open source network management package OpenNMS, and normally requires a bare minimum of implementation effort by a non-IT user.

 






Poster TUPPC124 [0.875 MB]
            
 


 



TUPPC126
Visualization of Experimental Data at the National Ignition Facility
879


 

M.S. Hutton, R.C. Bettenhausen, E.J. Bond, A.D. Casey, R.N. Fallejo, J.A. Liebman, A.A. Marsh, T. M. Pannell, S.M. Reisdorf, A.L. Warrick
                       LLNL, Livermore, California, USA

 


 

Funding: * This work performed under the auspices of the U.S. Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344. #LLNL-ABS-633252
An experiment on the National Ignition Facility (NIF) may produce hundreds of gigabytes of target diagnostic data. Raw and analyzed data are accumulated into the NIF Archive database. The Shot Data Systems team provides alternatives for accessing data including a web-based data visualization tool, a virtual file system for programmatic data access, a macro language for data integration, and a Wiki to support collaboration. The data visualization application in particular adapts dashboard user-interface design patterns popularized by the business intelligence software community. The dashboard canvas provides the ability to rapidly assemble tailored views of data directly from the NIF archive. This design has proven capable of satisfying most new visualization requirements in near real-time. The separate file system and macro feature-set support direct data access from a scientist’s computer using scientific languages such as IDL, Matlab and Mathematica. Underlying all these capabilities is a shared set of web services that provide APIs and transformation routines to the NIF Archive. The overall software architecture will be presented with an emphasis on data visualization.

 






Poster TUPPC126 [4.900 MB]
            
 


 



TUPPC128
Machine History Viewer for the Integrated Computer Control System of the National Ignition Facility
883


 

E.F. Wilson
                       LLNL, Livermore, California, USA

 


 

Funding: This work performed under the auspices of the U.S. Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344. #LLNL-ABS-633812
The Machine History Viewer is a recently developed capability of the Integrated Computer Control System (ICCS) software to the National Ignition Facility (NIF) that introduces the capability to analyze machine history data to troubleshoot equipment problems and to predict future failures. Flexible time correlation, text annotations, and multiple y-axis scales will help users determine cause and effect in the complex machine interactions at work in the NIF. Report criteria can be saved for easy modification and reuse. Integration into the already-familiar ICCS GUIs makes reporting easy to access for the operators. Reports can be created that will help analyze trends over long periods of time that lead to improved calibration and better detection of equipment failures. Faster identification of current failures and anticipation of potential failures will improve NIF availability and shot efficiency. A standalone version of this application is under development that will provide users remote access to real-time data and analysis allowing troubleshooting by experts without requiring them to come on-site.

 






Poster TUPPC128 [4.826 MB]
            
 


 



TUPPC129
NIF Device Health Monitoring
887


 

R. Fleming, C.M. Estes, J.M. Fisher, E.A. Stout
                       LLNL, Livermore, California, USA

 


 

Funding: * This work was performed under the auspices of the Lawrence Livermore National Security, LLC, (LLNS) under Contract No. DE-AC52-07NA27344. #LLNL-ABS-633794
The Integrated Computer Control System (ICCS) at the National Ignition Facility (NIF) uses Front-End Processors (FEP) controlling over 60,000 devices. Often device faults are not discovered until a device is needed during a shot, creating run-time errors that delay the laser shot. This paper discusses a new ICCS framework feature for FEPs to monitor devices and report its overall health, allowing for problem devices to be identified before they are needed. Each FEP has different devices and a unique definition of healthy. The ICCS software uses an object oriented approach using polymorphism so FEP’s can determine their health status and report it in a consistent way. This generic approach provides consistent GUI indication and the display of detailed information of device problems. It allows for operators to be informed quickly of faults and provides them with the information necessary to pin point and resolve issues. Operators now know before starting a shot if the control system is ready, thereby reducing time and material lost due to a failure and improving overall control system reliability and availability.

 






Poster TUPPC129 [2.318 MB]
            
 


 



TUPPC130
The Design of NSLS-II High Level Physics Applications
890


 

L. Yang, J. Choi, Y. Hidaka, Y. Li, G. Shen, G.M. Wang
                       BNL, Upton, Long Island, New York, USA

 


 

The NSLS-II high level physics applications are an effort from both controls and accelerator physics group. They are developed with the client-server approach, where the services are mainly provided by controls group in terms of web service or libraries.

 


 



TUPPC131
Synoptic Displays and Rapid Visual Application Development
893


 

B. Frak, K.A. Brown, T. D'Ottavio, M. Harvey, S. Nemesure
                       BNL, Upton, Long Island, New York, USA

 


 

Funding: Work supported by Brookhaven Science Associates, LLC under Contract No. DE-AC02-98CH10886 with the U.S. Department of Energy.
For a number of years there has been an increasing desire to adopt a synoptic display suite within BNL accelerator community. Initial interest in the precursors to the modern display suites like MEDM quickly fizzled out as our users found them aesthetically unappealing and cumbersome to use. Subsequent attempts to adopt Control System Studio (CSS) also fell short when work on the abstraction bridge between CSS and our control system stalled and was eventually abandoned. Most recently, we tested the open source version of a synoptic display developed at Fermilab. It, like its previously evaluated predecessors, also seemed rough around the edges, however a few implementation details made it more appealing than every single previously mentioned solution and after a brief evaluation we settled on Synoptic as our display suite of choice. This paper describes this adoption process and goes into details on several key changes and improvements made to the original implementation – a few of which made us rethink how we want to use this tool in the future.

 






Poster TUPPC131 [3.793 MB]
            
 


 



TUPPC132
Accelerator Control Data Visualization with Google Map
897


 

W. Fu, S. Nemesure
                       BNL, Upton, Long Island, New York, USA

 


 

Funding: Work supported by Brookhaven Science Associates, LLC under Contract No. DE-AC02-98CH10886 with the U.S. Department of Energy.
Using geological map data to serve as a visualization for components of a Controls System provides Main Control Room Operators an easy way to both identify and locate conditions within specific parts of an accelerator complex that may require attention. Google's Map API provides a simple and convenient way to display some of C-AD's Controls System data and provide location and status feedback using dynamic symbols and animations. This paper describes the details of how chipmunk and beam loss data visualization can be implemented for the AGS/RHIC Controls system. Most of the server side and client site software can be easily adapted to many other similar types of data visualizations.
Wenge Fu, Seth Nemesure, Brookhaven National Laboratory, Upton, NY 11973, USA 

 






Poster TUPPC132 [2.086 MB]
            
 


 



TUPPC133
Graphene: A Java Library for Real-Time Scientific Graphs
901


 

G. Carcassi, K. Shroff
                       BNL, Upton, Long Island, New York, USA

 


 

While there are a number of open source charting library available in Java, none of them seem to be suitable for real time scientific data, such as the one coming from control systems. Common shortcomings include: inadequate performance, too entangled with other scientific packages, concrete data object (which require copy operations), designed for small datasets, required running UI to produce any graph. Graphene is our effort to produce graphs that are suitable for scientific publishing, can be created without UI (e.g. in a web server), work on data defined through interfaces that allow no copy processing in a real time pipeline and are produced with adequate performance. The graphs are then integrated using pvmanager within Control System Studio.

 






Poster TUPPC133 [0.502 MB]
            
 


 



TUPPC134
Pvmanager: A Java Library for Real-Time Data Processing
903


 

G. Carcassi, K. Shroff
                       BNL, Upton, Long Island, New York, USA

 


 

Increasingly becoming the standard connection layer in Control System Studio, pvmanager is a Java library that allows to create well behaved applications that process real time data, such as the one coming from a control system. It takes care of the caching, queuing, rate decoupling and throttling, connection sharing, data aggregation and all the other details needed to make an application robust. Its fluent API allows to specify the detail for each pipeline declaratively in a compact way.

 






Poster TUPPC134 [0.518 MB]
            
 


 




