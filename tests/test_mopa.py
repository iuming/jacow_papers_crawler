#!/usr/bin/env python3
"""
ç›´æ¥æµ‹è¯•MOPA session
æˆ‘ä»¬ä¹‹å‰åœ¨fetch_webpageä¸­çœ‹åˆ°äº†MOPA001.pdfç­‰
"""

import asyncio
import aiohttp
import re
from urllib.parse import urljoin
from bs4 import BeautifulSoup
import sys

async def test_mopa_session():
    """æµ‹è¯•MOPA sessionï¼Œæˆ‘ä»¬ä¹‹å‰ç¡®è®¤æœ‰è®ºæ–‡"""
    base_url = "https://proceedings.jacow.org/ipac2023"
    session_url = f"{base_url}/session/238-mopa/index.html"
    
    async with aiohttp.ClientSession() as session:
        print(f"ğŸ” æµ‹è¯•MOPA session: {session_url}")
        
        try:
            async with session.get(session_url) as response:
                if response.status == 200:
                    content = await response.text()
                    print(f"âœ… é¡µé¢å¤§å°: {len(content)} å­—ç¬¦")
                    
                    # æ‰“å°éƒ¨åˆ†å†…å®¹æŸ¥çœ‹ç»“æ„
                    print(f"\nğŸ“‹ å†…å®¹æ ·æœ¬ (å‰500å­—ç¬¦):")
                    print(content[:500])
                    
                    # æŸ¥æ‰¾æ‰€æœ‰PDFé“¾æ¥
                    pdf_pattern = r'href="([^"]*\.pdf)"'
                    pdf_matches = re.findall(pdf_pattern, content)
                    
                    print(f"\nğŸ”— æ‰¾åˆ° {len(pdf_matches)} ä¸ªPDFé“¾æ¥:")
                    for i, pdf_url in enumerate(pdf_matches, 1):
                        print(f"  {i}. {pdf_url}")
                    
                    # æŸ¥æ‰¾MOPAæ¨¡å¼çš„è®ºæ–‡
                    mopa_pattern = r'MOPA\d+'
                    mopa_matches = re.findall(mopa_pattern, content)
                    
                    print(f"\nğŸ“„ æ‰¾åˆ°MOPAè®ºæ–‡ä»£ç : {len(mopa_matches)}ä¸ª")
                    for i, code in enumerate(set(mopa_matches), 1):
                        print(f"  {i}. {code}")
                    
                    # æŸ¥æ‰¾å®Œæ•´çš„PDF URLæ¨¡å¼
                    full_pdf_pattern = r'(https?://[^"]*MOPA\d+\.pdf)'
                    full_pdf_matches = re.findall(full_pdf_pattern, content)
                    
                    print(f"\nğŸ¯ å®Œæ•´PDF URLs: {len(full_pdf_matches)}ä¸ª")
                    for i, url in enumerate(full_pdf_matches, 1):
                        print(f"  {i}. {url}")
                        
                else:
                    print(f"âŒ HTTP {response.status}")
                    
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")

if __name__ == "__main__":
    if sys.platform.startswith('win'):
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    asyncio.run(test_mopa_session())
