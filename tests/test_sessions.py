#!/usr/bin/env python3
"""
ç›´æ¥æµ‹è¯•å·²çŸ¥çš„session URLs
åŸºäºä¹‹å‰fetch_webpageè·å–çš„å†…å®¹
"""

import asyncio
import aiohttp
import re
from urllib.parse import urljoin
from bs4 import BeautifulSoup
import sys

# åŸºäºä¹‹å‰çœ‹åˆ°çš„sessionåˆ—è¡¨
KNOWN_SESSIONS = [
    "221-supm",
    "172-moxd",
    "173-moyd",
    "163-mozd",
    "162-mozg",
    "175-mood",
    "174-moog",
    "238-mopa",  # è¿™ä¸ªæˆ‘ä»¬ä¹‹å‰æµ‹è¯•è¿‡
    "237-mopl",
    "236-mopm",
]


async def test_known_sessions():
    """æµ‹è¯•å·²çŸ¥çš„session URLs"""
    base_url = "https://proceedings.jacow.org/ipac2023"

    async with aiohttp.ClientSession() as session:
        print(f"ğŸ” æµ‹è¯•å·²çŸ¥sessions")

        working_sessions = []

        for session_code in KNOWN_SESSIONS[:5]:  # åªæµ‹è¯•å‰5ä¸ª
            session_path = f"{session_code}/index.html"
            full_url = urljoin(f"{base_url}/session/", session_path)

            print(f"\nğŸ“„ æµ‹è¯•: {full_url}")

            try:
                async with session.get(full_url) as response:
                    if response.status == 200:
                        content = await response.text()

                        # æŸ¥æ‰¾PDFé“¾æ¥
                        pdf_pattern = r'href="([^"]*\.pdf)"'
                        pdf_matches = re.findall(pdf_pattern, content)

                        individual_papers = []
                        for pdf_url in pdf_matches:
                            # æ£€æŸ¥æ˜¯å¦ä¸ºå•ç¯‡è®ºæ–‡
                            if re.search(
                                r"[A-Z]{2,4}\d{3}\.pdf$", pdf_url, re.IGNORECASE
                            ):
                                individual_papers.append(pdf_url)

                        print(f"  âœ… æˆåŠŸ! æ‰¾åˆ° {len(individual_papers)} ç¯‡å•ç‹¬è®ºæ–‡")
                        if individual_papers:
                            working_sessions.append(full_url)
                            for i, paper in enumerate(individual_papers[:3], 1):
                                print(f"    {i}. {paper}")
                            if len(individual_papers) > 3:
                                print(f"    ... è¿˜æœ‰ {len(individual_papers) - 3} ç¯‡")
                    else:
                        print(f"  âŒ HTTP {response.status}")

            except Exception as e:
                print(f"  âŒ é”™è¯¯: {e}")

        return working_sessions


if __name__ == "__main__":
    if sys.platform.startswith("win"):
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

    working_sessions = asyncio.run(test_known_sessions())
    print(f"\nğŸ‰ å·¥ä½œçš„sessions: {len(working_sessions)}ä¸ª")
    for url in working_sessions:
        print(f"  âœ… {url}")
